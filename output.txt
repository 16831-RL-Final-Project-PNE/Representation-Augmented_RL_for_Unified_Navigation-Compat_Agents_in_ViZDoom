=== Checking if RSSM params are in world_model optimizer ===
Missing RSSM parameters: 0


********** Iteration 0 ************
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.0558, device='cuda:0')
Mean prior_logit: tensor(0.0031, device='cuda:0') Std prior_logit: tensor(0.0420, device='cuda:0')
Mean deter_state: tensor(-0.0025, device='cuda:0') Std deter_state: tensor(0.0573, device='cuda:0')
Mean prior_logit: tensor(0.0015, device='cuda:0') Std prior_logit: tensor(0.0441, device='cuda:0')
Mean deter_state: tensor(-5.8974e-06, device='cuda:0') Std deter_state: tensor(0.0627, device='cuda:0')
Mean prior_logit: tensor(0.0031, device='cuda:0') Std prior_logit: tensor(0.0417, device='cuda:0')
Mean deter_state: tensor(0.0014, device='cuda:0') Std deter_state: tensor(0.0563, device='cuda:0')
Mean prior_logit: tensor(0.0037, device='cuda:0') Std prior_logit: tensor(0.0410, device='cuda:0')
Mean deter_state: tensor(0.0009, device='cuda:0') Std deter_state: tensor(0.0550, device='cuda:0')
Mean prior_logit: tensor(0.0044, device='cuda:0') Std prior_logit: tensor(0.0421, device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.0551, device='cuda:0')
Mean prior_logit: tensor(0.0028, device='cuda:0') Std prior_logit: tensor(0.0418, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0') Std deter_state: tensor(0.0530, device='cuda:0')
Mean prior_logit: tensor(0.0046, device='cuda:0') Std prior_logit: tensor(0.0421, device='cuda:0')
Mean deter_state: tensor(-0.0027, device='cuda:0') Std deter_state: tensor(0.0605, device='cuda:0')
Mean prior_logit: tensor(0.0022, device='cuda:0') Std prior_logit: tensor(0.0439, device='cuda:0')
Mean deter_state: tensor(0.0030, device='cuda:0') Std deter_state: tensor(0.0572, device='cuda:0')
Mean prior_logit: tensor(0.0016, device='cuda:0') Std prior_logit: tensor(0.0407, device='cuda:0')
Mean deter_state: tensor(-0.0011, device='cuda:0') Std deter_state: tensor(0.0542, device='cuda:0')
Mean prior_logit: tensor(0.0024, device='cuda:0') Std prior_logit: tensor(0.0414, device='cuda:0')
Mean deter_state: tensor(-0.0018, device='cuda:0') Std deter_state: tensor(0.0579, device='cuda:0')
Mean prior_logit: tensor(0.0039, device='cuda:0') Std prior_logit: tensor(0.0412, device='cuda:0')
Mean deter_state: tensor(-0.0005, device='cuda:0') Std deter_state: tensor(0.0566, device='cuda:0')
Mean prior_logit: tensor(0.0043, device='cuda:0') Std prior_logit: tensor(0.0417, device='cuda:0')
Mean deter_state: tensor(-0.0040, device='cuda:0') Std deter_state: tensor(0.0591, device='cuda:0')
Mean prior_logit: tensor(0.0026, device='cuda:0') Std prior_logit: tensor(0.0420, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.0592, device='cuda:0')
Mean prior_logit: tensor(0.0027, device='cuda:0') Std prior_logit: tensor(0.0423, device='cuda:0')
Mean deter_state: tensor(-0.0006, device='cuda:0') Std deter_state: tensor(0.0535, device='cuda:0')
Mean prior_logit: tensor(0.0022, device='cuda:0') Std prior_logit: tensor(0.0415, device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.0164, device='cuda:0')
Mean prior_logit: tensor(0.0038, device='cuda:0') Std prior_logit: tensor(0.0377, device='cuda:0')
Mean deter_state: tensor(-0.0008, device='cuda:0') Std deter_state: tensor(0.0561, device='cuda:0')
Mean prior_logit: tensor(0.0043, device='cuda:0') Std prior_logit: tensor(0.0413, device='cuda:0')
Mean deter_state: tensor(0.0011, device='cuda:0') Std deter_state: tensor(0.0550, device='cuda:0')
Mean prior_logit: tensor(0.0034, device='cuda:0') Std prior_logit: tensor(0.0419, device='cuda:0')
Mean deter_state: tensor(-0.0021, device='cuda:0') Std deter_state: tensor(0.0566, device='cuda:0')
Mean prior_logit: tensor(0.0030, device='cuda:0') Std prior_logit: tensor(0.0409, device='cuda:0')
Mean deter_state: tensor(-0.0026, device='cuda:0') Std deter_state: tensor(0.0527, device='cuda:0')
Mean prior_logit: tensor(0.0024, device='cuda:0') Std prior_logit: tensor(0.0411, device='cuda:0')
Mean deter_state: tensor(0.0009, device='cuda:0') Std deter_state: tensor(0.0560, device='cuda:0')
Mean prior_logit: tensor(0.0036, device='cuda:0') Std prior_logit: tensor(0.0417, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0') Std deter_state: tensor(0.0583, device='cuda:0')
Mean prior_logit: tensor(0.0033, device='cuda:0') Std prior_logit: tensor(0.0413, device='cuda:0')
Mean deter_state: tensor(-0.0011, device='cuda:0') Std deter_state: tensor(0.0538, device='cuda:0')
Mean prior_logit: tensor(0.0039, device='cuda:0') Std prior_logit: tensor(0.0435, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.0559, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0416, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.0571, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0415, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.0580, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0417, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0013, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.0667, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0442, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.1301, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0603, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0892, 0.0878, 0.0778, 0.0839, 0.0805, 0.0902, 0.0812, 0.0814, 0.0777,
        0.0824, 0.0819, 0.0859], device='cuda:0')
Mean deter_state: tensor(-0.0025, device='cuda:0') Std deter_state: tensor(0.1382, device='cuda:0')
Mean prior_logit: tensor(0.0001, device='cuda:0') Std prior_logit: tensor(0.0617, device='cuda:0')
Mean deter_state: tensor(-0.0008, device='cuda:0') Std deter_state: tensor(0.1348, device='cuda:0')
Mean prior_logit: tensor(0.0004, device='cuda:0') Std prior_logit: tensor(0.0623, device='cuda:0')
Mean deter_state: tensor(-0.0036, device='cuda:0') Std deter_state: tensor(0.1415, device='cuda:0')
Mean prior_logit: tensor(-0.0006, device='cuda:0') Std prior_logit: tensor(0.0629, device='cuda:0')
Mean deter_state: tensor(-0.0039, device='cuda:0') Std deter_state: tensor(0.1348, device='cuda:0')
Mean prior_logit: tensor(0.0011, device='cuda:0') Std prior_logit: tensor(0.0603, device='cuda:0')
Mean deter_state: tensor(-0.0039, device='cuda:0') Std deter_state: tensor(0.1373, device='cuda:0')
Mean prior_logit: tensor(0.0001, device='cuda:0') Std prior_logit: tensor(0.0605, device='cuda:0')
Mean deter_state: tensor(7.6409e-05, device='cuda:0') Std deter_state: tensor(0.1441, device='cuda:0')
Mean prior_logit: tensor(-0.0004, device='cuda:0') Std prior_logit: tensor(0.0646, device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.1398, device='cuda:0')
Mean prior_logit: tensor(0.0003, device='cuda:0') Std prior_logit: tensor(0.0627, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([26, 27, 20, 21, 30, 37, 20, 25, 16, 24, 25, 29]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_0.gif
Eval_AverageReturn : -151.8000030517578
Eval_StdReturn : 234.3086700439453
Eval_MaxReturn : 95.0
Eval_MinReturn : -390.0
Eval_AverageEpLen : 157.8000030517578
Train_AverageReturn : -206.39535522460938
Train_StdReturn : 222.0733184814453
Train_MaxReturn : 95.0
Train_MinReturn : -400.0
Train_AverageEpLen : 190.51162719726562
Train_EnvstepsSoFar : 8192.0
TimeSinceStart : 216.49129271507263
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 0.7763973563909531
Loss_Value : 0.3757618415169418
Loss_Entropy : 2.4830664873123167
Loss_Representation : 4.507939344644546
Loss_KL : 3.223596054315567
Loss_Obs : -0.035474194679409266
Loss_Reward : 0.7571307696402073
Loss_Discount : 0.5626867391169071
Loss_RawKL : 2.2799489196855576
mean_target : -0.11109696574276313
max_target : -0.013549687224440277
min_target : -0.14387353635829642
std_target : 0.044249116339778995
Done logging...

Current epsilon: 0.7226191070355269 at iteration 8192


********** Iteration 1 ************
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.1390, device='cuda:0')
Mean prior_logit: tensor(-0.0009, device='cuda:0') Std prior_logit: tensor(0.0614, device='cuda:0')
Mean deter_state: tensor(-0.0014, device='cuda:0') Std deter_state: tensor(0.1442, device='cuda:0')
Mean prior_logit: tensor(0.0006, device='cuda:0') Std prior_logit: tensor(0.0656, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.1313, device='cuda:0')
Mean prior_logit: tensor(0.0003, device='cuda:0') Std prior_logit: tensor(0.0600, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0') Std deter_state: tensor(0.1447, device='cuda:0')
Mean prior_logit: tensor(0.0012, device='cuda:0') Std prior_logit: tensor(0.0644, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.1393, device='cuda:0')
Mean prior_logit: tensor(0.0004, device='cuda:0') Std prior_logit: tensor(0.0624, device='cuda:0')
Mean deter_state: tensor(-0.0032, device='cuda:0') Std deter_state: tensor(0.1430, device='cuda:0')
Mean prior_logit: tensor(0.0002, device='cuda:0') Std prior_logit: tensor(0.0633, device='cuda:0')
Mean deter_state: tensor(-0.0027, device='cuda:0') Std deter_state: tensor(0.1425, device='cuda:0')
Mean prior_logit: tensor(0.0003, device='cuda:0') Std prior_logit: tensor(0.0631, device='cuda:0')
Mean deter_state: tensor(-0.0002, device='cuda:0') Std deter_state: tensor(0.1387, device='cuda:0')
Mean prior_logit: tensor(0.0003, device='cuda:0') Std prior_logit: tensor(0.0633, device='cuda:0')
Mean deter_state: tensor(-0.0028, device='cuda:0') Std deter_state: tensor(0.1380, device='cuda:0')
Mean prior_logit: tensor(-0.0002, device='cuda:0') Std prior_logit: tensor(0.0622, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0') Std deter_state: tensor(0.1391, device='cuda:0')
Mean prior_logit: tensor(0.0005, device='cuda:0') Std prior_logit: tensor(0.0625, device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.1405, device='cuda:0')
Mean prior_logit: tensor(0.0009, device='cuda:0') Std prior_logit: tensor(0.0643, device='cuda:0')
Mean deter_state: tensor(-0.0023, device='cuda:0') Std deter_state: tensor(0.1151, device='cuda:0')
Mean prior_logit: tensor(0.0008, device='cuda:0') Std prior_logit: tensor(0.0559, device='cuda:0')
Mean deter_state: tensor(-0.0023, device='cuda:0') Std deter_state: tensor(0.1431, device='cuda:0')
Mean prior_logit: tensor(-0.0001, device='cuda:0') Std prior_logit: tensor(0.0626, device='cuda:0')
Mean deter_state: tensor(-0.0040, device='cuda:0') Std deter_state: tensor(0.1348, device='cuda:0')
Mean prior_logit: tensor(0.0003, device='cuda:0') Std prior_logit: tensor(0.0605, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.1384, device='cuda:0')
Mean prior_logit: tensor(0.0002, device='cuda:0') Std prior_logit: tensor(0.0615, device='cuda:0')
Mean deter_state: tensor(-0.0021, device='cuda:0') Std deter_state: tensor(0.1347, device='cuda:0')
Mean prior_logit: tensor(0.0004, device='cuda:0') Std prior_logit: tensor(0.0614, device='cuda:0')
Mean deter_state: tensor(-0.0011, device='cuda:0') Std deter_state: tensor(0.1388, device='cuda:0')
Mean prior_logit: tensor(0.0008, device='cuda:0') Std prior_logit: tensor(0.0626, device='cuda:0')
Mean deter_state: tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.1645, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0693, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.1850, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0753, device='cuda:0', grad_fn=<StdBackward0>)
Imagined rewards:  tensor([-0.0224, -0.0320, -0.0873, -0.0858, -0.0771, -0.0984, -0.1000, -0.1037,
        -0.0810, -0.1062], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-0.3874, -0.4756, -0.5509, -0.5557, -0.5503, -0.5480, -0.5142, -0.4687,
        -0.4119], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-0.3874, -0.4756, -0.5509, -0.5557, -0.5503, -0.5480, -0.5142, -0.4687,
        -0.4119], device='cuda:0', grad_fn=<SelectBackward0>)
Mean deter_state: tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2112, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0830, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.1018, 0.1370, 0.0430, 0.1001, 0.0464, 0.1236, 0.0871, 0.0702, 0.0526,
        0.0530, 0.0952, 0.0900], device='cuda:0')
Mean deter_state: tensor(-0.0009, device='cuda:0') Std deter_state: tensor(0.2364, device='cuda:0')
Mean prior_logit: tensor(0.0002, device='cuda:0') Std prior_logit: tensor(0.0912, device='cuda:0')
Mean deter_state: tensor(-0.0030, device='cuda:0') Std deter_state: tensor(0.2420, device='cuda:0')
Mean prior_logit: tensor(-0.0011, device='cuda:0') Std prior_logit: tensor(0.0912, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0') Std deter_state: tensor(0.2356, device='cuda:0')
Mean prior_logit: tensor(0.0001, device='cuda:0') Std prior_logit: tensor(0.0908, device='cuda:0')
Mean deter_state: tensor(-0.0024, device='cuda:0') Std deter_state: tensor(0.2497, device='cuda:0')
Mean prior_logit: tensor(-0.0006, device='cuda:0') Std prior_logit: tensor(0.0938, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([25, 71,  2, 31,  6, 59, 29, 14, 10,  3, 25, 25]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_1.gif
Eval_AverageReturn : -112.80000305175781
Eval_StdReturn : 220.462158203125
Eval_MaxReturn : 95.0
Eval_MinReturn : -385.0
Eval_AverageEpLen : 137.39999389648438
Train_AverageReturn : -206.39535522460938
Train_StdReturn : 224.09561157226562
Train_MaxReturn : 95.0
Train_MinReturn : -395.0
Train_AverageEpLen : 190.51162719726562
Train_EnvstepsSoFar : 16384.0
TimeSinceStart : 430.9057734012604
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 4.598385626077652
Loss_Value : -0.44888631752692165
Loss_Entropy : 2.4022893846035003
Loss_Representation : 2.833525574207306
Loss_KL : 3.0006927728652952
Loss_Obs : -1.0355153605341911
Loss_Reward : 0.670184350758791
Loss_Discount : 0.19816380720585586
Loss_RawKL : 2.0241425722837447
mean_target : -0.5349513560533523
max_target : -0.38085234314203265
min_target : -0.6297470897436142
std_target : 0.0856374990195036
Done logging...

Current epsilon: 0.5822546625285524 at iteration 16384


********** Iteration 2 ************
Mean deter_state: tensor(-0.0003, device='cuda:0') Std deter_state: tensor(0.2365, device='cuda:0')
Mean prior_logit: tensor(-0.0008, device='cuda:0') Std prior_logit: tensor(0.0912, device='cuda:0')
Mean deter_state: tensor(-0.0054, device='cuda:0') Std deter_state: tensor(0.2405, device='cuda:0')
Mean prior_logit: tensor(-0.0008, device='cuda:0') Std prior_logit: tensor(0.0913, device='cuda:0')
Mean deter_state: tensor(-0.0007, device='cuda:0') Std deter_state: tensor(0.2347, device='cuda:0')
Mean prior_logit: tensor(-0.0007, device='cuda:0') Std prior_logit: tensor(0.0904, device='cuda:0')
Mean deter_state: tensor(-0.0034, device='cuda:0') Std deter_state: tensor(0.2417, device='cuda:0')
Mean prior_logit: tensor(-0.0004, device='cuda:0') Std prior_logit: tensor(0.0920, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.2527, device='cuda:0')
Mean prior_logit: tensor(-0.0008, device='cuda:0') Std prior_logit: tensor(0.0966, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0') Std deter_state: tensor(0.2501, device='cuda:0')
Mean prior_logit: tensor(0.0002, device='cuda:0') Std prior_logit: tensor(0.0966, device='cuda:0')
Mean deter_state: tensor(-0.0007, device='cuda:0') Std deter_state: tensor(0.2403, device='cuda:0')
Mean prior_logit: tensor(-0.0020, device='cuda:0') Std prior_logit: tensor(0.0923, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.2481, device='cuda:0')
Mean prior_logit: tensor(-0.0010, device='cuda:0') Std prior_logit: tensor(0.0950, device='cuda:0')
Mean deter_state: tensor(-0.0005, device='cuda:0') Std deter_state: tensor(0.2420, device='cuda:0')
Mean prior_logit: tensor(-0.0017, device='cuda:0') Std prior_logit: tensor(0.0938, device='cuda:0')
Mean deter_state: tensor(-0.0029, device='cuda:0') Std deter_state: tensor(0.2501, device='cuda:0')
Mean prior_logit: tensor(-0.0007, device='cuda:0') Std prior_logit: tensor(0.0951, device='cuda:0')
Mean deter_state: tensor(-0.0023, device='cuda:0') Std deter_state: tensor(0.2566, device='cuda:0')
Mean prior_logit: tensor(-0.0012, device='cuda:0') Std prior_logit: tensor(0.0973, device='cuda:0')
Mean deter_state: tensor(-0.0040, device='cuda:0') Std deter_state: tensor(0.2397, device='cuda:0')
Mean prior_logit: tensor(-0.0013, device='cuda:0') Std prior_logit: tensor(0.0908, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0') Std deter_state: tensor(0.2423, device='cuda:0')
Mean prior_logit: tensor(-0.0013, device='cuda:0') Std prior_logit: tensor(0.0940, device='cuda:0')
Mean deter_state: tensor(-0.0024, device='cuda:0') Std deter_state: tensor(0.2520, device='cuda:0')
Mean prior_logit: tensor(-0.0007, device='cuda:0') Std prior_logit: tensor(0.0968, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0') Std deter_state: tensor(0.2409, device='cuda:0')
Mean prior_logit: tensor(-0.0010, device='cuda:0') Std prior_logit: tensor(0.0920, device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.2542, device='cuda:0')
Mean prior_logit: tensor(-0.0009, device='cuda:0') Std prior_logit: tensor(0.0964, device='cuda:0')
Mean deter_state: tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2393, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0943, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2446, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0972, device='cuda:0', grad_fn=<StdBackward0>)
Imagined rewards:  tensor([-0.0500, -0.0542, -0.0737, -0.0886, -0.0819, -0.1077, -0.1074, -0.1171,
        -0.0952, -0.1093], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-0.9615, -1.0591, -1.1248, -1.1447, -1.1279, -1.1085, -1.0473, -0.9782,
        -0.8912], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-0.9615, -1.0591, -1.1248, -1.1447, -1.1279, -1.1085, -1.0473, -0.9782,
        -0.8912], device='cuda:0', grad_fn=<SelectBackward0>)
Mean deter_state: tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2640, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.1044, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2712, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.1066, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0015, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2982, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.1146, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0398, 0.3252, 0.0058, 0.0488, 0.0088, 0.3276, 0.0418, 0.0334, 0.0158,
        0.0134, 0.0323, 0.1073], device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([  9,  85,   1,   4,   2, 105,   6,   9,   5,   5,   1,  68]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_2.gif
Eval_AverageReturn : -247.1999969482422
Eval_StdReturn : 199.76626586914062
Eval_MaxReturn : 69.0
Eval_MinReturn : -385.0
Eval_AverageEpLen : 221.0
Train_AverageReturn : -196.56817626953125
Train_StdReturn : 226.029296875
Train_MaxReturn : 95.0
Train_MinReturn : -390.0
Train_AverageEpLen : 186.18182373046875
Train_EnvstepsSoFar : 24576.0
TimeSinceStart : 655.9097909927368
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 12.736861681938171
Loss_Value : -0.2619372267276049
Loss_Entropy : 1.7539373844861985
Loss_Representation : 2.5122039556503295
Loss_KL : 3.0006709456443788
Loss_Obs : -1.1846104711294174
Loss_Reward : 0.6462552348151803
Loss_Discount : 0.04988825051113963
Loss_RawKL : 1.954610785841942
mean_target : -1.4327087953686715
max_target : -1.157047139108181
min_target : -1.6468313366174698
std_target : 0.16921720281243324
Done logging...

Current epsilon: 0.4711819480299418 at iteration 24576


********** Iteration 3 ************
Mean deter_state: tensor(0.0007, device='cuda:0') Std deter_state: tensor(0.3163, device='cuda:0')
Mean prior_logit: tensor(-0.0012, device='cuda:0') Std prior_logit: tensor(0.1210, device='cuda:0')
Mean deter_state: tensor(-0.0028, device='cuda:0') Std deter_state: tensor(0.3231, device='cuda:0')
Mean prior_logit: tensor(-0.0023, device='cuda:0') Std prior_logit: tensor(0.1225, device='cuda:0')
Mean deter_state: tensor(-0.0040, device='cuda:0') Std deter_state: tensor(0.3287, device='cuda:0')
Mean prior_logit: tensor(-0.0025, device='cuda:0') Std prior_logit: tensor(0.1240, device='cuda:0')
Mean deter_state: tensor(0.0025, device='cuda:0') Std deter_state: tensor(0.2979, device='cuda:0')
Mean prior_logit: tensor(-0.0013, device='cuda:0') Std prior_logit: tensor(0.1141, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.3163, device='cuda:0')
Mean prior_logit: tensor(-0.0014, device='cuda:0') Std prior_logit: tensor(0.1199, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.3246, device='cuda:0')
Mean prior_logit: tensor(-0.0006, device='cuda:0') Std prior_logit: tensor(0.1224, device='cuda:0')
Mean deter_state: tensor(-0.0005, device='cuda:0') Std deter_state: tensor(0.2902, device='cuda:0')
Mean prior_logit: tensor(-0.0018, device='cuda:0') Std prior_logit: tensor(0.1137, device='cuda:0')
Mean deter_state: tensor(-0.0018, device='cuda:0') Std deter_state: tensor(0.3151, device='cuda:0')
Mean prior_logit: tensor(-0.0012, device='cuda:0') Std prior_logit: tensor(0.1184, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0') Std deter_state: tensor(0.3264, device='cuda:0')
Mean prior_logit: tensor(-0.0022, device='cuda:0') Std prior_logit: tensor(0.1241, device='cuda:0')
Mean deter_state: tensor(-0.0014, device='cuda:0') Std deter_state: tensor(0.3101, device='cuda:0')
Mean prior_logit: tensor(-0.0018, device='cuda:0') Std prior_logit: tensor(0.1192, device='cuda:0')
Mean deter_state: tensor(-0.0027, device='cuda:0') Std deter_state: tensor(0.3224, device='cuda:0')
Mean prior_logit: tensor(-0.0014, device='cuda:0') Std prior_logit: tensor(0.1221, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.1455, device='cuda:0')
Mean prior_logit: tensor(-0.0006, device='cuda:0') Std prior_logit: tensor(0.0673, device='cuda:0')
Mean deter_state: tensor(-0.0036, device='cuda:0') Std deter_state: tensor(0.3228, device='cuda:0')
Mean prior_logit: tensor(-0.0010, device='cuda:0') Std prior_logit: tensor(0.1227, device='cuda:0')
Mean deter_state: tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5095, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.1866, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4918, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.1849, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0161, 0.2471, 0.0027, 0.0131, 0.0110, 0.3081, 0.0583, 0.0540, 0.0164,
        0.0105, 0.0136, 0.2492], device='cuda:0')
Mean deter_state: tensor(-0.0015, device='cuda:0') Std deter_state: tensor(0.1583, device='cuda:0')
Mean prior_logit: tensor(-0.0002, device='cuda:0') Std prior_logit: tensor(0.0737, device='cuda:0')
Mean deter_state: tensor(0.0052, device='cuda:0') Std deter_state: tensor(0.3496, device='cuda:0')
Mean prior_logit: tensor(-0.0031, device='cuda:0') Std prior_logit: tensor(0.1405, device='cuda:0')
Mean deter_state: tensor(0.0051, device='cuda:0') Std deter_state: tensor(0.5314, device='cuda:0')
Mean prior_logit: tensor(-0.0043, device='cuda:0') Std prior_logit: tensor(0.1992, device='cuda:0')
Mean deter_state: tensor(0.0045, device='cuda:0') Std deter_state: tensor(0.5033, device='cuda:0')
Mean prior_logit: tensor(-0.0038, device='cuda:0') Std prior_logit: tensor(0.1902, device='cuda:0')
Mean deter_state: tensor(0.0009, device='cuda:0') Std deter_state: tensor(0.3569, device='cuda:0')
Mean prior_logit: tensor(-0.0020, device='cuda:0') Std prior_logit: tensor(0.1429, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 4, 60,  1,  2, 10, 79, 34, 28,  7,  3,  7, 65]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_3.gif
Eval_AverageReturn : -298.20001220703125
Eval_StdReturn : 173.9217071533203
Eval_MaxReturn : 71.0
Eval_MinReturn : -390.0
Eval_AverageEpLen : 248.39999389648438
Train_AverageReturn : -286.3235168457031
Train_StdReturn : 189.7459259033203
Train_MaxReturn : 95.0
Train_MinReturn : -390.0
Train_AverageEpLen : 240.94117736816406
Train_EnvstepsSoFar : 32768.0
TimeSinceStart : 886.4574103355408
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 23.567117977142335
Loss_Value : -0.057641909684753044
Loss_Entropy : 1.7153182238340379
Loss_Representation : 1.8503472536802292
Loss_KL : 3.0352102398872374
Loss_Obs : -1.2813223779201508
Loss_Reward : 0.06377347644884139
Loss_Discount : 0.03268591011874378
Loss_RawKL : 2.225017601251602
mean_target : -2.635679432749748
max_target : -2.3246383547782896
min_target : -2.8771126747131346
std_target : 0.19136811643838883
Done logging...

Current epsilon: 0.38328826562750956 at iteration 32768


********** Iteration 4 ************
Mean deter_state: tensor(0.0049, device='cuda:0') Std deter_state: tensor(0.5281, device='cuda:0')
Mean prior_logit: tensor(-0.0041, device='cuda:0') Std prior_logit: tensor(0.1987, device='cuda:0')
Mean deter_state: tensor(0.0035, device='cuda:0') Std deter_state: tensor(0.5231, device='cuda:0')
Mean prior_logit: tensor(-0.0051, device='cuda:0') Std prior_logit: tensor(0.1976, device='cuda:0')
Mean deter_state: tensor(-0.0008, device='cuda:0') Std deter_state: tensor(0.1333, device='cuda:0')
Mean prior_logit: tensor(0.0001, device='cuda:0') Std prior_logit: tensor(0.0660, device='cuda:0')
Mean deter_state: tensor(0.0044, device='cuda:0') Std deter_state: tensor(0.5056, device='cuda:0')
Mean prior_logit: tensor(-0.0041, device='cuda:0') Std prior_logit: tensor(0.1906, device='cuda:0')
Mean deter_state: tensor(0.0070, device='cuda:0') Std deter_state: tensor(0.5128, device='cuda:0')
Mean prior_logit: tensor(-0.0040, device='cuda:0') Std prior_logit: tensor(0.1933, device='cuda:0')
Mean deter_state: tensor(0.0048, device='cuda:0') Std deter_state: tensor(0.5021, device='cuda:0')
Mean prior_logit: tensor(-0.0041, device='cuda:0') Std prior_logit: tensor(0.1904, device='cuda:0')
Mean deter_state: tensor(-0.0009, device='cuda:0') Std deter_state: tensor(0.0673, device='cuda:0')
Mean prior_logit: tensor(0.0018, device='cuda:0') Std prior_logit: tensor(0.0450, device='cuda:0')
Mean deter_state: tensor(0.0073, device='cuda:0') Std deter_state: tensor(0.5173, device='cuda:0')
Mean prior_logit: tensor(-0.0050, device='cuda:0') Std prior_logit: tensor(0.1955, device='cuda:0')
Mean deter_state: tensor(0.0033, device='cuda:0') Std deter_state: tensor(0.4609, device='cuda:0')
Mean prior_logit: tensor(-0.0042, device='cuda:0') Std prior_logit: tensor(0.1785, device='cuda:0')
Mean deter_state: tensor(0.0048, device='cuda:0') Std deter_state: tensor(0.5096, device='cuda:0')
Mean prior_logit: tensor(-0.0046, device='cuda:0') Std prior_logit: tensor(0.1920, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.3219, device='cuda:0')
Mean prior_logit: tensor(-0.0009, device='cuda:0') Std prior_logit: tensor(0.1312, device='cuda:0')
Mean deter_state: tensor(0.0063, device='cuda:0') Std deter_state: tensor(0.4215, device='cuda:0')
Mean prior_logit: tensor(-0.0039, device='cuda:0') Std prior_logit: tensor(0.1647, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.5247, device='cuda:0')
Mean prior_logit: tensor(-0.0038, device='cuda:0') Std prior_logit: tensor(0.1974, device='cuda:0')
Mean deter_state: tensor(0.0028, device='cuda:0') Std deter_state: tensor(0.3584, device='cuda:0')
Mean prior_logit: tensor(-0.0027, device='cuda:0') Std prior_logit: tensor(0.1426, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.2764, device='cuda:0')
Mean prior_logit: tensor(-7.7083e-05, device='cuda:0') Std prior_logit: tensor(0.1138, device='cuda:0')
Mean deter_state: tensor(0.0043, device='cuda:0') Std deter_state: tensor(0.5206, device='cuda:0')
Mean prior_logit: tensor(-0.0045, device='cuda:0') Std prior_logit: tensor(0.1957, device='cuda:0')
Current action distribution:
tensor([0.0156, 0.1095, 0.0036, 0.0097, 0.0227, 0.1206, 0.1272, 0.0569, 0.0283,
        0.0140, 0.0150, 0.4769], device='cuda:0')
Mean deter_state: tensor(0.0037, device='cuda:0') Std deter_state: tensor(0.4178, device='cuda:0')
Mean prior_logit: tensor(-0.0127, device='cuda:0') Std prior_logit: tensor(0.2704, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.3152, device='cuda:0')
Mean prior_logit: tensor(-0.0106, device='cuda:0') Std prior_logit: tensor(0.2174, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.2594, device='cuda:0')
Mean prior_logit: tensor(-0.0099, device='cuda:0') Std prior_logit: tensor(0.1867, device='cuda:0')
Count of actions: (array([ 1,  4,  5,  6,  7, 11]), array([  2,   1,   1,   2,   2, 111]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_4.gif
Eval_AverageReturn : -119.4000015258789
Eval_StdReturn : 182.15444946289062
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 149.1999969482422
Train_AverageReturn : -238.84616088867188
Train_StdReturn : 215.83274841308594
Train_MaxReturn : 95.0
Train_MinReturn : -395.0
Train_AverageEpLen : 210.05128479003906
Train_EnvstepsSoFar : 40960.0
TimeSinceStart : 1097.5370478630066
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 30.818173837661742
Loss_Value : -0.042926202956005
Loss_Entropy : 1.5584485508501529
Loss_Representation : 1.8173495680093765
Loss_KL : 3.2290590047836303
Loss_Obs : -1.315740042924881
Loss_Reward : -0.13375185923650862
Loss_Discount : 0.037782466039061546
Loss_RawKL : 2.5866561770439147
mean_target : -3.439766561985016
max_target : -3.1552862346172335
min_target : -3.643102949857712
std_target : 0.17122030928730964
Done logging...

Current epsilon: 0.3137365360138764 at iteration 40960


********** Iteration 5 ************
Mean deter_state: tensor(-0.0017, device='cuda:0') Std deter_state: tensor(0.2672, device='cuda:0')
Mean prior_logit: tensor(-0.0105, device='cuda:0') Std prior_logit: tensor(0.1915, device='cuda:0')
Mean deter_state: tensor(0.0026, device='cuda:0') Std deter_state: tensor(0.3627, device='cuda:0')
Mean prior_logit: tensor(-0.0120, device='cuda:0') Std prior_logit: tensor(0.2404, device='cuda:0')
Mean deter_state: tensor(0.0030, device='cuda:0') Std deter_state: tensor(0.4382, device='cuda:0')
Mean prior_logit: tensor(-0.0130, device='cuda:0') Std prior_logit: tensor(0.2808, device='cuda:0')
Mean deter_state: tensor(0.0028, device='cuda:0') Std deter_state: tensor(0.4327, device='cuda:0')
Mean prior_logit: tensor(-0.0119, device='cuda:0') Std prior_logit: tensor(0.2781, device='cuda:0')
Mean deter_state: tensor(0.0040, device='cuda:0') Std deter_state: tensor(0.4560, device='cuda:0')
Mean prior_logit: tensor(-0.0134, device='cuda:0') Std prior_logit: tensor(0.2908, device='cuda:0')
Mean deter_state: tensor(0.0020, device='cuda:0') Std deter_state: tensor(0.2644, device='cuda:0')
Mean prior_logit: tensor(-0.0097, device='cuda:0') Std prior_logit: tensor(0.1902, device='cuda:0')
Mean deter_state: tensor(0.0013, device='cuda:0') Std deter_state: tensor(0.4192, device='cuda:0')
Mean prior_logit: tensor(-0.0129, device='cuda:0') Std prior_logit: tensor(0.2710, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0') Std deter_state: tensor(0.3594, device='cuda:0')
Mean prior_logit: tensor(-0.0121, device='cuda:0') Std prior_logit: tensor(0.2417, device='cuda:0')
Mean deter_state: tensor(0.0056, device='cuda:0') Std deter_state: tensor(0.4501, device='cuda:0')
Mean prior_logit: tensor(-0.0138, device='cuda:0') Std prior_logit: tensor(0.2872, device='cuda:0')
Mean deter_state: tensor(0.0020, device='cuda:0') Std deter_state: tensor(0.3089, device='cuda:0')
Mean prior_logit: tensor(-0.0097, device='cuda:0') Std prior_logit: tensor(0.2115, device='cuda:0')
Mean deter_state: tensor(0.0022, device='cuda:0') Std deter_state: tensor(0.3834, device='cuda:0')
Mean prior_logit: tensor(-0.0121, device='cuda:0') Std prior_logit: tensor(0.2534, device='cuda:0')
Mean deter_state: tensor(0.0027, device='cuda:0') Std deter_state: tensor(0.4241, device='cuda:0')
Mean prior_logit: tensor(-0.0128, device='cuda:0') Std prior_logit: tensor(0.2725, device='cuda:0')
Mean deter_state: tensor(0.0035, device='cuda:0') Std deter_state: tensor(0.4307, device='cuda:0')
Mean prior_logit: tensor(-0.0119, device='cuda:0') Std prior_logit: tensor(0.2743, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0') Std deter_state: tensor(0.0992, device='cuda:0')
Mean prior_logit: tensor(-0.0033, device='cuda:0') Std prior_logit: tensor(0.0766, device='cuda:0')
Mean deter_state: tensor(0.0054, device='cuda:0') Std deter_state: tensor(0.4095, device='cuda:0')
Mean prior_logit: tensor(-0.0132, device='cuda:0') Std prior_logit: tensor(0.2650, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0') Std deter_state: tensor(0.2677, device='cuda:0')
Mean prior_logit: tensor(-0.0104, device='cuda:0') Std prior_logit: tensor(0.1907, device='cuda:0')
Mean deter_state: tensor(0.0047, device='cuda:0') Std deter_state: tensor(0.4225, device='cuda:0')
Mean prior_logit: tensor(-0.0119, device='cuda:0') Std prior_logit: tensor(0.2736, device='cuda:0')
Mean deter_state: tensor(0.0020, device='cuda:0') Std deter_state: tensor(0.3727, device='cuda:0')
Mean prior_logit: tensor(-0.0119, device='cuda:0') Std prior_logit: tensor(0.2482, device='cuda:0')
Mean deter_state: tensor(0.0014, device='cuda:0') Std deter_state: tensor(0.3047, device='cuda:0')
Mean prior_logit: tensor(-0.0100, device='cuda:0') Std prior_logit: tensor(0.2130, device='cuda:0')
Mean deter_state: tensor(0.0025, device='cuda:0') Std deter_state: tensor(0.4595, device='cuda:0')
Mean prior_logit: tensor(-0.0134, device='cuda:0') Std prior_logit: tensor(0.2932, device='cuda:0')
Mean deter_state: tensor(0.0050, device='cuda:0') Std deter_state: tensor(0.4190, device='cuda:0')
Mean prior_logit: tensor(-0.0126, device='cuda:0') Std prior_logit: tensor(0.2712, device='cuda:0')
Imagined rewards:  tensor([-0.0271, -0.0461, -0.0814, -0.0927, -0.0926, -0.1018, -0.0943, -0.0679,
        -0.0936, -0.1154], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-2.3986, -2.7015, -2.8620, -2.9047, -2.9158, -2.9028, -2.8828, -2.8652,
        -2.8736], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-2.3986, -2.7015, -2.8620, -2.9047, -2.9158, -2.9028, -2.8828, -2.8652,
        -2.8736], device='cuda:0', grad_fn=<SelectBackward0>)
Mean deter_state: tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2464, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0273, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.2272, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2397, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0274, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.2248, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([8.8088e-04, 5.0261e-03, 1.8320e-04, 4.5315e-04, 1.5205e-03, 5.3859e-03,
        6.4033e-03, 2.6410e-03, 2.7736e-03, 1.0303e-03, 1.1155e-03, 9.7259e-01],
       device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.3465, device='cuda:0')
Mean prior_logit: tensor(-0.0385, device='cuda:0') Std prior_logit: tensor(0.3395, device='cuda:0')
Mean deter_state: tensor(-0.0064, device='cuda:0') Std deter_state: tensor(0.2035, device='cuda:0')
Mean prior_logit: tensor(-0.0435, device='cuda:0') Std prior_logit: tensor(0.2721, device='cuda:0')
Mean deter_state: tensor(-0.0015, device='cuda:0') Std deter_state: tensor(0.3382, device='cuda:0')
Mean prior_logit: tensor(-0.0416, device='cuda:0') Std prior_logit: tensor(0.3434, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.3804, device='cuda:0')
Mean prior_logit: tensor(-0.0366, device='cuda:0') Std prior_logit: tensor(0.3588, device='cuda:0')
Count of actions: (array([ 8, 11]), array([1, 5]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_5.gif
Eval_AverageReturn : -146.89999389648438
Eval_StdReturn : 228.7769317626953
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 153.0
Train_AverageReturn : -129.7058868408203
Train_StdReturn : 172.3748016357422
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 160.62745666503906
Train_EnvstepsSoFar : 49152.0
TimeSinceStart : 1305.9524309635162
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 30.688353395462038
Loss_Value : -0.21713600893272086
Loss_Entropy : 0.15638651594053954
Loss_Representation : 3.1393034368753434
Loss_KL : 3.7731746256351473
Loss_Obs : -1.313726857304573
Loss_Reward : 0.6375948118977248
Loss_Discount : 0.042260876018553974
Loss_RawKL : 3.6126178085803984
mean_target : -3.4113120555877687
max_target : -3.2154769778251646
min_target : -3.550435721874237
std_target : 0.11843214174732566
Done logging...

Current epsilon: 0.2586990980544666 at iteration 49152


********** Iteration 6 ************
Mean deter_state: tensor(-0.0055, device='cuda:0') Std deter_state: tensor(0.2964, device='cuda:0')
Mean prior_logit: tensor(-0.0435, device='cuda:0') Std prior_logit: tensor(0.3294, device='cuda:0')
Mean deter_state: tensor(-0.0004, device='cuda:0') Std deter_state: tensor(0.3492, device='cuda:0')
Mean prior_logit: tensor(-0.0387, device='cuda:0') Std prior_logit: tensor(0.3453, device='cuda:0')
Mean deter_state: tensor(-0.0002, device='cuda:0') Std deter_state: tensor(0.3718, device='cuda:0')
Mean prior_logit: tensor(-0.0381, device='cuda:0') Std prior_logit: tensor(0.3565, device='cuda:0')
Mean deter_state: tensor(-0.0026, device='cuda:0') Std deter_state: tensor(0.3310, device='cuda:0')
Mean prior_logit: tensor(-0.0395, device='cuda:0') Std prior_logit: tensor(0.3327, device='cuda:0')
Mean deter_state: tensor(-0.0035, device='cuda:0') Std deter_state: tensor(0.3429, device='cuda:0')
Mean prior_logit: tensor(-0.0405, device='cuda:0') Std prior_logit: tensor(0.3425, device='cuda:0')
Mean deter_state: tensor(-0.0014, device='cuda:0') Std deter_state: tensor(0.2765, device='cuda:0')
Mean prior_logit: tensor(-0.0404, device='cuda:0') Std prior_logit: tensor(0.3056, device='cuda:0')
Mean deter_state: tensor(-0.0036, device='cuda:0') Std deter_state: tensor(0.3126, device='cuda:0')
Mean prior_logit: tensor(-0.0379, device='cuda:0') Std prior_logit: tensor(0.3202, device='cuda:0')
Mean deter_state: tensor(-0.0113, device='cuda:0') Std deter_state: tensor(0.2158, device='cuda:0')
Mean prior_logit: tensor(-0.0511, device='cuda:0') Std prior_logit: tensor(0.2860, device='cuda:0')
Mean deter_state: tensor(0.0012, device='cuda:0') Std deter_state: tensor(0.4125, device='cuda:0')
Mean prior_logit: tensor(-0.0362, device='cuda:0') Std prior_logit: tensor(0.3753, device='cuda:0')
Mean deter_state: tensor(0.0010, device='cuda:0') Std deter_state: tensor(0.3440, device='cuda:0')
Mean prior_logit: tensor(-0.0372, device='cuda:0') Std prior_logit: tensor(0.3346, device='cuda:0')
Mean deter_state: tensor(-0.0065, device='cuda:0') Std deter_state: tensor(0.2267, device='cuda:0')
Mean prior_logit: tensor(-0.0479, device='cuda:0') Std prior_logit: tensor(0.3011, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0') Std deter_state: tensor(0.3213, device='cuda:0')
Mean prior_logit: tensor(-0.0414, device='cuda:0') Std prior_logit: tensor(0.3351, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0') Std deter_state: tensor(0.2926, device='cuda:0')
Mean prior_logit: tensor(-0.0410, device='cuda:0') Std prior_logit: tensor(0.3162, device='cuda:0')
Mean deter_state: tensor(-0.0053, device='cuda:0') Std deter_state: tensor(0.2445, device='cuda:0')
Mean prior_logit: tensor(-0.0408, device='cuda:0') Std prior_logit: tensor(0.2900, device='cuda:0')
Mean deter_state: tensor(-0.0082, device='cuda:0') Std deter_state: tensor(0.2010, device='cuda:0')
Mean prior_logit: tensor(-0.0411, device='cuda:0') Std prior_logit: tensor(0.2656, device='cuda:0')
Mean deter_state: tensor(-0.0104, device='cuda:0') Std deter_state: tensor(0.1979, device='cuda:0')
Mean prior_logit: tensor(-0.0492, device='cuda:0') Std prior_logit: tensor(0.2800, device='cuda:0')
Mean deter_state: tensor(-0.0033, device='cuda:0') Std deter_state: tensor(0.3030, device='cuda:0')
Mean prior_logit: tensor(-0.0365, device='cuda:0') Std prior_logit: tensor(0.3139, device='cuda:0')
Mean deter_state: tensor(-0.0031, device='cuda:0') Std deter_state: tensor(0.3000, device='cuda:0')
Mean prior_logit: tensor(-0.0403, device='cuda:0') Std prior_logit: tensor(0.3190, device='cuda:0')
Mean deter_state: tensor(-0.0031, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3065, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0398, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.3173, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3032, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0411, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.3200, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4120, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0623, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4506, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4352, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0604, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4612, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4541, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0565, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4676, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([1.7786e-05, 1.1204e-04, 3.4251e-06, 9.2654e-06, 3.1988e-05, 9.5373e-05,
        1.1535e-04, 6.2343e-05, 7.2124e-05, 2.1344e-05, 2.5420e-05, 9.9943e-01],
       device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.4788, device='cuda:0')
Mean prior_logit: tensor(-0.0518, device='cuda:0') Std prior_logit: tensor(0.4709, device='cuda:0')
Mean deter_state: tensor(0.0012, device='cuda:0') Std deter_state: tensor(0.4943, device='cuda:0')
Mean prior_logit: tensor(-0.0431, device='cuda:0') Std prior_logit: tensor(0.4717, device='cuda:0')
Mean deter_state: tensor(-0.0086, device='cuda:0') Std deter_state: tensor(0.3158, device='cuda:0')
Mean prior_logit: tensor(-0.1099, device='cuda:0') Std prior_logit: tensor(0.5171, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.4038, device='cuda:0')
Mean prior_logit: tensor(-0.0742, device='cuda:0') Std prior_logit: tensor(0.4685, device='cuda:0')
Count of actions: (array([11]), array([104]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_6.gif
Eval_AverageReturn : -224.0
Eval_StdReturn : 204.13623046875
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 202.0
Train_AverageReturn : -182.0
Train_StdReturn : 179.99545288085938
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 186.18182373046875
Train_EnvstepsSoFar : 57344.0
TimeSinceStart : 1523.7150859832764
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 42.41908283233643
Loss_Value : -0.03888722804404097
Loss_Entropy : 0.004967693728394807
Loss_Representation : 1.1162098437547683
Loss_KL : 3.150335544347763
Loss_Obs : -1.4375058084726333
Loss_Reward : -0.6294303003698587
Loss_Discount : 0.03281039567664266
Loss_RawKL : 3.101208710670471
mean_target : -4.713267886638642
max_target : -4.4480595827102665
min_target : -4.904440593719483
std_target : 0.16223813081160188
Done logging...

Current epsilon: 0.21514705996766492 at iteration 57344


********** Iteration 7 ************
Mean deter_state: tensor(-0.0140, device='cuda:0') Std deter_state: tensor(0.3096, device='cuda:0')
Mean prior_logit: tensor(-0.1153, device='cuda:0') Std prior_logit: tensor(0.5325, device='cuda:0')
Mean deter_state: tensor(0.0037, device='cuda:0') Std deter_state: tensor(0.5057, device='cuda:0')
Mean prior_logit: tensor(-0.0426, device='cuda:0') Std prior_logit: tensor(0.4735, device='cuda:0')
Mean deter_state: tensor(-0.0011, device='cuda:0') Std deter_state: tensor(0.4524, device='cuda:0')
Mean prior_logit: tensor(-0.0548, device='cuda:0') Std prior_logit: tensor(0.4709, device='cuda:0')
Mean deter_state: tensor(-0.0111, device='cuda:0') Std deter_state: tensor(0.1975, device='cuda:0')
Mean prior_logit: tensor(-0.0893, device='cuda:0') Std prior_logit: tensor(0.3766, device='cuda:0')
Mean deter_state: tensor(0.0028, device='cuda:0') Std deter_state: tensor(0.5012, device='cuda:0')
Mean prior_logit: tensor(-0.0432, device='cuda:0') Std prior_logit: tensor(0.4708, device='cuda:0')
Mean deter_state: tensor(0.0002, device='cuda:0') Std deter_state: tensor(0.4795, device='cuda:0')
Mean prior_logit: tensor(-0.0555, device='cuda:0') Std prior_logit: tensor(0.4739, device='cuda:0')
Mean deter_state: tensor(0.0010, device='cuda:0') Std deter_state: tensor(0.4937, device='cuda:0')
Mean prior_logit: tensor(-0.0450, device='cuda:0') Std prior_logit: tensor(0.4711, device='cuda:0')
Mean deter_state: tensor(0.0014, device='cuda:0') Std deter_state: tensor(0.4463, device='cuda:0')
Mean prior_logit: tensor(-0.0542, device='cuda:0') Std prior_logit: tensor(0.4655, device='cuda:0')
Mean deter_state: tensor(-0.0116, device='cuda:0') Std deter_state: tensor(0.2814, device='cuda:0')
Mean prior_logit: tensor(-0.1216, device='cuda:0') Std prior_logit: tensor(0.5295, device='cuda:0')
Mean deter_state: tensor(0.0030, device='cuda:0') Std deter_state: tensor(0.5243, device='cuda:0')
Mean prior_logit: tensor(-0.0431, device='cuda:0') Std prior_logit: tensor(0.4863, device='cuda:0')
Mean deter_state: tensor(-1.7607e-05, device='cuda:0') Std deter_state: tensor(0.4302, device='cuda:0')
Mean prior_logit: tensor(-0.0617, device='cuda:0') Std prior_logit: tensor(0.4603, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0') Std deter_state: tensor(0.3840, device='cuda:0')
Mean prior_logit: tensor(-0.0699, device='cuda:0') Std prior_logit: tensor(0.4528, device='cuda:0')
Mean deter_state: tensor(0.0028, device='cuda:0') Std deter_state: tensor(0.5057, device='cuda:0')
Mean prior_logit: tensor(-0.0405, device='cuda:0') Std prior_logit: tensor(0.4704, device='cuda:0')
Mean deter_state: tensor(-0.0131, device='cuda:0') Std deter_state: tensor(0.2998, device='cuda:0')
Mean prior_logit: tensor(-0.1230, device='cuda:0') Std prior_logit: tensor(0.5510, device='cuda:0')
Mean deter_state: tensor(0.0006, device='cuda:0') Std deter_state: tensor(0.4840, device='cuda:0')
Mean prior_logit: tensor(-0.0466, device='cuda:0') Std prior_logit: tensor(0.4711, device='cuda:0')
Mean deter_state: tensor(-0.0069, device='cuda:0') Std deter_state: tensor(0.3645, device='cuda:0')
Mean prior_logit: tensor(-0.0900, device='cuda:0') Std prior_logit: tensor(0.4856, device='cuda:0')
Mean deter_state: tensor(-0.0073, device='cuda:0') Std deter_state: tensor(0.3235, device='cuda:0')
Mean prior_logit: tensor(-0.1026, device='cuda:0') Std prior_logit: tensor(0.5021, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.4755, device='cuda:0')
Mean prior_logit: tensor(-0.0482, device='cuda:0') Std prior_logit: tensor(0.4649, device='cuda:0')
Mean deter_state: tensor(0.0062, device='cuda:0') Std deter_state: tensor(0.5450, device='cuda:0')
Mean prior_logit: tensor(-0.0376, device='cuda:0') Std prior_logit: tensor(0.4965, device='cuda:0')
Mean deter_state: tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3963, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0714, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4671, device='cuda:0', grad_fn=<StdBackward0>)
Imagined rewards:  tensor([-0.0694, -0.0878, -0.0994, -0.0765, -0.0892, -0.0660, -0.0788, -0.0957,
        -0.0849, -0.0962], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-5.0279, -5.1186, -5.1392, -5.1098, -5.0977, -5.0637, -5.0527, -5.0237,
        -4.9666], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-5.0279, -5.1186, -5.1392, -5.1098, -5.0977, -5.0637, -5.0527, -5.0237,
        -4.9666], device='cuda:0', grad_fn=<SelectBackward0>)
Mean deter_state: tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4217, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0753, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5087, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4484, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0707, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5221, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4239, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0745, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5080, device='cuda:0', grad_fn=<StdBackward0>)
Imagined rewards:  tensor([-0.0768, -0.0843, -0.0911, -0.0914, -0.0975, -0.0985, -0.0963, -0.0920,
        -0.1002, -0.1055], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-5.5407, -5.6348, -5.6545, -5.6360, -5.6081, -5.5670, -5.5146, -5.4562,
        -5.4013], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-5.5407, -5.6348, -5.6545, -5.6360, -5.6081, -5.5670, -5.5146, -5.4562,
        -5.4013], device='cuda:0', grad_fn=<SelectBackward0>)
Current action distribution:
tensor([1.3781e-05, 8.8449e-05, 2.6840e-06, 7.1680e-06, 2.4998e-05, 7.5177e-05,
        9.2324e-05, 4.8950e-05, 5.8997e-05, 1.6548e-05, 1.9542e-05, 9.9955e-01],
       device='cuda:0')
Mean deter_state: tensor(-0.0127, device='cuda:0') Std deter_state: tensor(0.3102, device='cuda:0')
Mean prior_logit: tensor(-0.1375, device='cuda:0') Std prior_logit: tensor(0.5933, device='cuda:0')
Mean deter_state: tensor(0.0011, device='cuda:0') Std deter_state: tensor(0.4240, device='cuda:0')
Mean prior_logit: tensor(-0.0638, device='cuda:0') Std prior_logit: tensor(0.4946, device='cuda:0')
Mean deter_state: tensor(-0.0109, device='cuda:0') Std deter_state: tensor(0.3214, device='cuda:0')
Mean prior_logit: tensor(-0.1366, device='cuda:0') Std prior_logit: tensor(0.5943, device='cuda:0')
Count of actions: (array([11]), array([6]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_7.gif
Eval_AverageReturn : -85.5
Eval_StdReturn : 137.33990478515625
Eval_MaxReturn : 95.0
Eval_MinReturn : -304.0
Eval_AverageEpLen : 139.0
Train_AverageReturn : -139.4901885986328
Train_StdReturn : 170.5509490966797
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 160.62745666503906
Train_EnvstepsSoFar : 65536.0
TimeSinceStart : 1730.4192173480988
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 48.74049892425537
Loss_Value : -0.2993885989300907
Loss_Entropy : 0.003976672870339826
Loss_Representation : -0.11509227752685547
Loss_KL : 3.053036618232727
Loss_Obs : -1.470169597864151
Loss_Reward : -1.734397279471159
Loss_Discount : 0.03643798669800162
Loss_RawKL : 3.0198453783988954
mean_target : -5.415639066696167
max_target : -5.20848822593689
min_target : -5.557184040546417
std_target : 0.1252713181078434
Done logging...

Current epsilon: 0.18068360941763928 at iteration 65536


********** Iteration 8 ************
Mean deter_state: tensor(-0.0097, device='cuda:0') Std deter_state: tensor(0.3494, device='cuda:0')
Mean prior_logit: tensor(-0.1192, device='cuda:0') Std prior_logit: tensor(0.5660, device='cuda:0')
Mean deter_state: tensor(-0.0115, device='cuda:0') Std deter_state: tensor(0.3334, device='cuda:0')
Mean prior_logit: tensor(-0.1192, device='cuda:0') Std prior_logit: tensor(0.5526, device='cuda:0')
Mean deter_state: tensor(-0.0153, device='cuda:0') Std deter_state: tensor(0.3173, device='cuda:0')
Mean prior_logit: tensor(-0.1402, device='cuda:0') Std prior_logit: tensor(0.5971, device='cuda:0')
Mean deter_state: tensor(-0.0006, device='cuda:0') Std deter_state: tensor(0.4875, device='cuda:0')
Mean prior_logit: tensor(-0.0598, device='cuda:0') Std prior_logit: tensor(0.5197, device='cuda:0')
Mean deter_state: tensor(0.0023, device='cuda:0') Std deter_state: tensor(0.4929, device='cuda:0')
Mean prior_logit: tensor(-0.0589, device='cuda:0') Std prior_logit: tensor(0.5256, device='cuda:0')
Mean deter_state: tensor(-0.0005, device='cuda:0') Std deter_state: tensor(0.4595, device='cuda:0')
Mean prior_logit: tensor(-0.0707, device='cuda:0') Std prior_logit: tensor(0.5236, device='cuda:0')
Mean deter_state: tensor(0.0010, device='cuda:0') Std deter_state: tensor(0.5149, device='cuda:0')
Mean prior_logit: tensor(-0.0476, device='cuda:0') Std prior_logit: tensor(0.5316, device='cuda:0')
Mean deter_state: tensor(0.0015, device='cuda:0') Std deter_state: tensor(0.5108, device='cuda:0')
Mean prior_logit: tensor(-0.0554, device='cuda:0') Std prior_logit: tensor(0.5350, device='cuda:0')
Mean deter_state: tensor(-0.0094, device='cuda:0') Std deter_state: tensor(0.3661, device='cuda:0')
Mean prior_logit: tensor(-0.1080, device='cuda:0') Std prior_logit: tensor(0.5399, device='cuda:0')
Mean deter_state: tensor(-0.0072, device='cuda:0') Std deter_state: tensor(0.3271, device='cuda:0')
Mean prior_logit: tensor(-0.0858, device='cuda:0') Std prior_logit: tensor(0.4855, device='cuda:0')
Mean deter_state: tensor(-0.0070, device='cuda:0') Std deter_state: tensor(0.3259, device='cuda:0')
Mean prior_logit: tensor(-0.1117, device='cuda:0') Std prior_logit: tensor(0.5400, device='cuda:0')
Mean deter_state: tensor(-0.0002, device='cuda:0') Std deter_state: tensor(0.4306, device='cuda:0')
Mean prior_logit: tensor(-0.0619, device='cuda:0') Std prior_logit: tensor(0.5019, device='cuda:0')
Mean deter_state: tensor(-0.0140, device='cuda:0') Std deter_state: tensor(0.3235, device='cuda:0')
Mean prior_logit: tensor(-0.1254, device='cuda:0') Std prior_logit: tensor(0.5709, device='cuda:0')
Mean deter_state: tensor(-0.0013, device='cuda:0') Std deter_state: tensor(0.4459, device='cuda:0')
Mean prior_logit: tensor(-0.0702, device='cuda:0') Std prior_logit: tensor(0.5109, device='cuda:0')
Mean deter_state: tensor(0.0051, device='cuda:0') Std deter_state: tensor(0.5167, device='cuda:0')
Mean prior_logit: tensor(-0.0420, device='cuda:0') Std prior_logit: tensor(0.5296, device='cuda:0')
Mean deter_state: tensor(-0.0046, device='cuda:0') Std deter_state: tensor(0.3636, device='cuda:0')
Mean prior_logit: tensor(-0.1043, device='cuda:0') Std prior_logit: tensor(0.5317, device='cuda:0')
Mean deter_state: tensor(0.0049, device='cuda:0') Std deter_state: tensor(0.5250, device='cuda:0')
Mean prior_logit: tensor(-0.0444, device='cuda:0') Std prior_logit: tensor(0.5318, device='cuda:0')
Mean deter_state: tensor(-0.0028, device='cuda:0') Std deter_state: tensor(0.4399, device='cuda:0')
Mean prior_logit: tensor(-0.0792, device='cuda:0') Std prior_logit: tensor(0.5219, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.4802, device='cuda:0')
Mean prior_logit: tensor(-0.0643, device='cuda:0') Std prior_logit: tensor(0.5244, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.4832, device='cuda:0')
Mean prior_logit: tensor(-0.0594, device='cuda:0') Std prior_logit: tensor(0.5198, device='cuda:0')
Mean deter_state: tensor(-0.0004, device='cuda:0') Std deter_state: tensor(0.4354, device='cuda:0')
Mean prior_logit: tensor(-0.0608, device='cuda:0') Std prior_logit: tensor(0.5049, device='cuda:0')
Mean deter_state: tensor(0.0034, device='cuda:0') Std deter_state: tensor(0.5044, device='cuda:0')
Mean prior_logit: tensor(-0.0511, device='cuda:0') Std prior_logit: tensor(0.5265, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4414, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0773, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5364, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4305, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0942, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5726, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([1.3893e-05, 9.0325e-05, 2.7208e-06, 7.2041e-06, 2.5377e-05, 7.7492e-05,
        9.5900e-05, 4.9587e-05, 6.2273e-05, 1.6730e-05, 1.9555e-05, 9.9954e-01],
       device='cuda:0')
Mean deter_state: tensor(-0.0011, device='cuda:0') Std deter_state: tensor(0.4620, device='cuda:0')
Mean prior_logit: tensor(-0.0628, device='cuda:0') Std prior_logit: tensor(0.5590, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0') Std deter_state: tensor(0.4216, device='cuda:0')
Mean prior_logit: tensor(-0.0792, device='cuda:0') Std prior_logit: tensor(0.5553, device='cuda:0')
Mean deter_state: tensor(-0.0124, device='cuda:0') Std deter_state: tensor(0.3271, device='cuda:0')
Mean prior_logit: tensor(-0.1408, device='cuda:0') Std prior_logit: tensor(0.6116, device='cuda:0')
Count of actions: (array([11]), array([6]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_8.gif
Eval_AverageReturn : -142.89999389648438
Eval_StdReturn : 167.00445556640625
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 165.6999969482422
Train_AverageReturn : -199.2558135986328
Train_StdReturn : 187.52352905273438
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 190.51162719726562
Train_EnvstepsSoFar : 73728.0
TimeSinceStart : 1940.7853853702545
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 54.89309968948364
Loss_Value : -0.354918622225523
Loss_Entropy : 0.00406605806783773
Loss_Representation : -0.3178259372711182
Loss_KL : 3.149604320526123
Loss_Obs : -1.474958711862564
Loss_Reward : -2.0245363116264343
Loss_Discount : 0.03206477160565555
Loss_RawKL : 3.133892238140106
mean_target : -6.099261856079101
max_target : -5.89807813167572
min_target : -6.23586413860321
std_target : 0.12172445114701987
Done logging...

Current epsilon: 0.15341210902432012 at iteration 73728


********** Iteration 9 ************
Mean deter_state: tensor(0.0064, device='cuda:0') Std deter_state: tensor(0.5793, device='cuda:0')
Mean prior_logit: tensor(-0.0496, device='cuda:0') Std prior_logit: tensor(0.6100, device='cuda:0')
Mean deter_state: tensor(-0.0088, device='cuda:0') Std deter_state: tensor(0.3511, device='cuda:0')
Mean prior_logit: tensor(-0.1303, device='cuda:0') Std prior_logit: tensor(0.6004, device='cuda:0')
Mean deter_state: tensor(-0.0030, device='cuda:0') Std deter_state: tensor(0.4495, device='cuda:0')
Mean prior_logit: tensor(-0.0817, device='cuda:0') Std prior_logit: tensor(0.5570, device='cuda:0')
Mean deter_state: tensor(-0.0081, device='cuda:0') Std deter_state: tensor(0.3438, device='cuda:0')
Mean prior_logit: tensor(-0.1348, device='cuda:0') Std prior_logit: tensor(0.6036, device='cuda:0')
Mean deter_state: tensor(0.0046, device='cuda:0') Std deter_state: tensor(0.5147, device='cuda:0')
Mean prior_logit: tensor(-0.0580, device='cuda:0') Std prior_logit: tensor(0.5763, device='cuda:0')
Mean deter_state: tensor(0.0058, device='cuda:0') Std deter_state: tensor(0.5606, device='cuda:0')
Mean prior_logit: tensor(-0.0503, device='cuda:0') Std prior_logit: tensor(0.5969, device='cuda:0')
Mean deter_state: tensor(0.0060, device='cuda:0') Std deter_state: tensor(0.5707, device='cuda:0')
Mean prior_logit: tensor(-0.0537, device='cuda:0') Std prior_logit: tensor(0.6073, device='cuda:0')
Mean deter_state: tensor(0.0051, device='cuda:0') Std deter_state: tensor(0.5373, device='cuda:0')
Mean prior_logit: tensor(-0.0492, device='cuda:0') Std prior_logit: tensor(0.5907, device='cuda:0')
Mean deter_state: tensor(0.0059, device='cuda:0') Std deter_state: tensor(0.5644, device='cuda:0')
Mean prior_logit: tensor(-0.0473, device='cuda:0') Std prior_logit: tensor(0.6006, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.5543, device='cuda:0')
Mean prior_logit: tensor(-0.0545, device='cuda:0') Std prior_logit: tensor(0.5920, device='cuda:0')
Mean deter_state: tensor(0.0056, device='cuda:0') Std deter_state: tensor(0.5775, device='cuda:0')
Mean prior_logit: tensor(-0.0517, device='cuda:0') Std prior_logit: tensor(0.6138, device='cuda:0')
Mean deter_state: tensor(-0.0039, device='cuda:0') Std deter_state: tensor(0.3899, device='cuda:0')
Mean prior_logit: tensor(-0.0851, device='cuda:0') Std prior_logit: tensor(0.5423, device='cuda:0')
Mean deter_state: tensor(-0.0087, device='cuda:0') Std deter_state: tensor(0.3474, device='cuda:0')
Mean prior_logit: tensor(-0.1287, device='cuda:0') Std prior_logit: tensor(0.5948, device='cuda:0')
Mean deter_state: tensor(0.0006, device='cuda:0') Std deter_state: tensor(0.4825, device='cuda:0')
Mean prior_logit: tensor(-0.0805, device='cuda:0') Std prior_logit: tensor(0.5656, device='cuda:0')
Mean deter_state: tensor(0.0032, device='cuda:0') Std deter_state: tensor(0.5634, device='cuda:0')
Mean prior_logit: tensor(-0.0570, device='cuda:0') Std prior_logit: tensor(0.6035, device='cuda:0')
Mean deter_state: tensor(0.0057, device='cuda:0') Std deter_state: tensor(0.5704, device='cuda:0')
Mean prior_logit: tensor(-0.0504, device='cuda:0') Std prior_logit: tensor(0.6063, device='cuda:0')
Mean deter_state: tensor(0.0046, device='cuda:0') Std deter_state: tensor(0.5327, device='cuda:0')
Mean prior_logit: tensor(-0.0554, device='cuda:0') Std prior_logit: tensor(0.5891, device='cuda:0')
Mean deter_state: tensor(-0.0101, device='cuda:0') Std deter_state: tensor(0.3732, device='cuda:0')
Mean prior_logit: tensor(-0.1397, device='cuda:0') Std prior_logit: tensor(0.6261, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0') Std deter_state: tensor(0.0346, device='cuda:0')
Mean prior_logit: tensor(-0.0133, device='cuda:0') Std prior_logit: tensor(0.0796, device='cuda:0')
Mean deter_state: tensor(-0.0048, device='cuda:0') Std deter_state: tensor(0.3450, device='cuda:0')
Mean prior_logit: tensor(-0.0885, device='cuda:0') Std prior_logit: tensor(0.5138, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4553, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0869, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5839, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0025, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.1772, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0441, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.2715, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4540, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0868, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5822, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4578, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0904, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5920, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4653, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0837, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5815, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0034, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4535, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0964, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6068, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([1.5696e-05, 1.0497e-04, 3.0439e-06, 8.0568e-06, 2.9178e-05, 9.1249e-05,
        1.1434e-04, 5.6959e-05, 7.5670e-05, 1.9005e-05, 2.1905e-05, 9.9946e-01],
       device='cuda:0')
Mean deter_state: tensor(0.0039, device='cuda:0') Std deter_state: tensor(0.5199, device='cuda:0')
Mean prior_logit: tensor(-0.0600, device='cuda:0') Std prior_logit: tensor(0.5995, device='cuda:0')
Mean deter_state: tensor(0.0044, device='cuda:0') Std deter_state: tensor(0.5764, device='cuda:0')
Mean prior_logit: tensor(-0.0516, device='cuda:0') Std prior_logit: tensor(0.6203, device='cuda:0')
Mean deter_state: tensor(-0.0112, device='cuda:0') Std deter_state: tensor(0.2308, device='cuda:0')
Mean prior_logit: tensor(-0.1174, device='cuda:0') Std prior_logit: tensor(0.4702, device='cuda:0')
Mean deter_state: tensor(0.0041, device='cuda:0') Std deter_state: tensor(0.5132, device='cuda:0')
Mean prior_logit: tensor(-0.0609, device='cuda:0') Std prior_logit: tensor(0.6072, device='cuda:0')
Mean deter_state: tensor(-0.0007, device='cuda:0') Std deter_state: tensor(0.4957, device='cuda:0')
Mean prior_logit: tensor(-0.0786, device='cuda:0') Std prior_logit: tensor(0.5920, device='cuda:0')
Count of actions: (array([11]), array([216]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_9.gif
Eval_AverageReturn : -127.69999694824219
Eval_StdReturn : 180.355224609375
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 154.5
Train_AverageReturn : -192.32557678222656
Train_StdReturn : 194.43569946289062
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 190.51162719726562
Train_EnvstepsSoFar : 81920.0
TimeSinceStart : 2153.741034269333
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 60.10649452209473
Loss_Value : -0.3997061125934124
Loss_Entropy : 0.004752605909015983
Loss_Representation : -0.8241497099399566
Loss_KL : 3.033060371875763
Loss_Obs : -1.510604065656662
Loss_Reward : -2.3775197982788088
Loss_Discount : 0.030913775926455854
Loss_RawKL : 3.0187686920166015
mean_target : -6.678533673286438
max_target : -6.4827494621276855
min_target : -6.8134304761886595
std_target : 0.11904576253145933
Done logging...

Current epsilon: 0.13183171815129263 at iteration 81920


********** Iteration 10 ************
Mean deter_state: tensor(0.0071, device='cuda:0') Std deter_state: tensor(0.5674, device='cuda:0')
Mean prior_logit: tensor(-0.0550, device='cuda:0') Std prior_logit: tensor(0.6138, device='cuda:0')
Mean deter_state: tensor(0.0015, device='cuda:0') Std deter_state: tensor(0.5191, device='cuda:0')
Mean prior_logit: tensor(-0.0676, device='cuda:0') Std prior_logit: tensor(0.5890, device='cuda:0')
Mean deter_state: tensor(-0.0145, device='cuda:0') Std deter_state: tensor(0.3284, device='cuda:0')
Mean prior_logit: tensor(-0.1531, device='cuda:0') Std prior_logit: tensor(0.6431, device='cuda:0')
Mean deter_state: tensor(0.0060, device='cuda:0') Std deter_state: tensor(0.5689, device='cuda:0')
Mean prior_logit: tensor(-0.0480, device='cuda:0') Std prior_logit: tensor(0.6253, device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.4773, device='cuda:0')
Mean prior_logit: tensor(-0.0883, device='cuda:0') Std prior_logit: tensor(0.5834, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0') Std deter_state: tensor(0.3887, device='cuda:0')
Mean prior_logit: tensor(-0.0912, device='cuda:0') Std prior_logit: tensor(0.5630, device='cuda:0')
Mean deter_state: tensor(0.0046, device='cuda:0') Std deter_state: tensor(0.5493, device='cuda:0')
Mean prior_logit: tensor(-0.0589, device='cuda:0') Std prior_logit: tensor(0.6109, device='cuda:0')
Mean deter_state: tensor(2.6835e-05, device='cuda:0') Std deter_state: tensor(0.5239, device='cuda:0')
Mean prior_logit: tensor(-0.0700, device='cuda:0') Std prior_logit: tensor(0.6037, device='cuda:0')
Mean deter_state: tensor(-0.0092, device='cuda:0') Std deter_state: tensor(0.2401, device='cuda:0')
Mean prior_logit: tensor(-0.1233, device='cuda:0') Std prior_logit: tensor(0.4982, device='cuda:0')
Mean deter_state: tensor(-0.0030, device='cuda:0') Std deter_state: tensor(0.4624, device='cuda:0')
Mean prior_logit: tensor(-0.0947, device='cuda:0') Std prior_logit: tensor(0.5890, device='cuda:0')
Mean deter_state: tensor(0.0109, device='cuda:0') Std deter_state: tensor(0.5744, device='cuda:0')
Mean prior_logit: tensor(-0.0494, device='cuda:0') Std prior_logit: tensor(0.6232, device='cuda:0')
Mean deter_state: tensor(0.0039, device='cuda:0') Std deter_state: tensor(0.5371, device='cuda:0')
Mean prior_logit: tensor(-0.0721, device='cuda:0') Std prior_logit: tensor(0.6114, device='cuda:0')
Mean deter_state: tensor(-0.0064, device='cuda:0') Std deter_state: tensor(0.4721, device='cuda:0')
Mean prior_logit: tensor(-0.0934, device='cuda:0') Std prior_logit: tensor(0.5911, device='cuda:0')
Mean deter_state: tensor(0.0028, device='cuda:0') Std deter_state: tensor(0.5758, device='cuda:0')
Mean prior_logit: tensor(-0.0552, device='cuda:0') Std prior_logit: tensor(0.6245, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.5252, device='cuda:0')
Mean prior_logit: tensor(-0.0680, device='cuda:0') Std prior_logit: tensor(0.5961, device='cuda:0')
Mean deter_state: tensor(0.0058, device='cuda:0') Std deter_state: tensor(0.5815, device='cuda:0')
Mean prior_logit: tensor(-0.0536, device='cuda:0') Std prior_logit: tensor(0.6259, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.4782, device='cuda:0')
Mean prior_logit: tensor(-0.0911, device='cuda:0') Std prior_logit: tensor(0.6002, device='cuda:0')
Mean deter_state: tensor(0.0025, device='cuda:0') Std deter_state: tensor(0.5063, device='cuda:0')
Mean prior_logit: tensor(-0.0674, device='cuda:0') Std prior_logit: tensor(0.5929, device='cuda:0')
Mean deter_state: tensor(-0.0013, device='cuda:0') Std deter_state: tensor(0.4757, device='cuda:0')
Mean prior_logit: tensor(-0.0750, device='cuda:0') Std prior_logit: tensor(0.5706, device='cuda:0')
Mean deter_state: tensor(-0.0099, device='cuda:0') Std deter_state: tensor(0.3853, device='cuda:0')
Mean prior_logit: tensor(-0.1368, device='cuda:0') Std prior_logit: tensor(0.6268, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4719, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0891, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6032, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4601, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0919, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6066, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4578, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1017, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6212, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4621, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0931, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6083, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2896, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0629, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4159, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4596, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0957, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6154, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0027, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4528, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0942, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5950, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([2.2133e-05, 1.5276e-04, 4.1458e-06, 1.1154e-05, 4.1977e-05, 1.3717e-04,
        1.7142e-04, 8.1331e-05, 1.1643e-04, 2.7074e-05, 3.0725e-05, 9.9920e-01],
       device='cuda:0')
Mean deter_state: tensor(0.0036, device='cuda:0') Std deter_state: tensor(0.5493, device='cuda:0')
Mean prior_logit: tensor(-0.0616, device='cuda:0') Std prior_logit: tensor(0.6350, device='cuda:0')
Count of actions: (array([11]), array([104]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_10.gif
Eval_AverageReturn : -175.39999389648438
Eval_StdReturn : 204.4936065673828
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 174.0
Train_AverageReturn : -153.93617248535156
Train_StdReturn : 162.58042907714844
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 174.29786682128906
Train_EnvstepsSoFar : 90112.0
TimeSinceStart : 2367.493365764618
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 65.14986934661866
Loss_Value : -0.44476846382021906
Loss_Entropy : 0.006889469013549388
Loss_Representation : -0.5655201017856598
Loss_KL : 3.20283465385437
Loss_Obs : -1.5364704608917237
Loss_Reward : -2.2650629322975875
Loss_Discount : 0.033178624836727975
Loss_RawKL : 3.2028345823287965
mean_target : -7.238926529884338
max_target : -7.0585264444351195
min_target : -7.354176044464111
std_target : 0.10707630142569542
Done logging...

Current epsilon: 0.11475479669424161 at iteration 90112


********** Iteration 11 ************
Mean deter_state: tensor(-0.0123, device='cuda:0') Std deter_state: tensor(0.3893, device='cuda:0')
Mean prior_logit: tensor(-0.1569, device='cuda:0') Std prior_logit: tensor(0.6782, device='cuda:0')
Mean deter_state: tensor(0.0082, device='cuda:0') Std deter_state: tensor(0.5917, device='cuda:0')
Mean prior_logit: tensor(-0.0657, device='cuda:0') Std prior_logit: tensor(0.6495, device='cuda:0')
Mean deter_state: tensor(-0.0077, device='cuda:0') Std deter_state: tensor(0.4034, device='cuda:0')
Mean prior_logit: tensor(-0.1425, device='cuda:0') Std prior_logit: tensor(0.6464, device='cuda:0')
Mean deter_state: tensor(-0.0083, device='cuda:0') Std deter_state: tensor(0.3885, device='cuda:0')
Mean prior_logit: tensor(-0.1490, device='cuda:0') Std prior_logit: tensor(0.6585, device='cuda:0')
Mean deter_state: tensor(-0.0111, device='cuda:0') Std deter_state: tensor(0.3868, device='cuda:0')
Mean prior_logit: tensor(-0.1463, device='cuda:0') Std prior_logit: tensor(0.6579, device='cuda:0')
Mean deter_state: tensor(0.0021, device='cuda:0') Std deter_state: tensor(0.5551, device='cuda:0')
Mean prior_logit: tensor(-0.0782, device='cuda:0') Std prior_logit: tensor(0.6274, device='cuda:0')
Mean deter_state: tensor(0.0050, device='cuda:0') Std deter_state: tensor(0.5831, device='cuda:0')
Mean prior_logit: tensor(-0.0630, device='cuda:0') Std prior_logit: tensor(0.6423, device='cuda:0')
Mean deter_state: tensor(0.0072, device='cuda:0') Std deter_state: tensor(0.6045, device='cuda:0')
Mean prior_logit: tensor(-0.0546, device='cuda:0') Std prior_logit: tensor(0.6490, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.5700, device='cuda:0')
Mean prior_logit: tensor(-0.0671, device='cuda:0') Std prior_logit: tensor(0.6415, device='cuda:0')
Mean deter_state: tensor(-0.0090, device='cuda:0') Std deter_state: tensor(0.3920, device='cuda:0')
Mean prior_logit: tensor(-0.1326, device='cuda:0') Std prior_logit: tensor(0.6314, device='cuda:0')
Mean deter_state: tensor(0.0076, device='cuda:0') Std deter_state: tensor(0.5852, device='cuda:0')
Mean prior_logit: tensor(-0.0594, device='cuda:0') Std prior_logit: tensor(0.6391, device='cuda:0')
Mean deter_state: tensor(0.0047, device='cuda:0') Std deter_state: tensor(0.5934, device='cuda:0')
Mean prior_logit: tensor(-0.0612, device='cuda:0') Std prior_logit: tensor(0.6444, device='cuda:0')
Mean deter_state: tensor(0.0022, device='cuda:0') Std deter_state: tensor(0.5276, device='cuda:0')
Mean prior_logit: tensor(-0.0715, device='cuda:0') Std prior_logit: tensor(0.6175, device='cuda:0')
Mean deter_state: tensor(-0.0164, device='cuda:0') Std deter_state: tensor(0.3391, device='cuda:0')
Mean prior_logit: tensor(-0.1659, device='cuda:0') Std prior_logit: tensor(0.6632, device='cuda:0')
Mean deter_state: tensor(0.0034, device='cuda:0') Std deter_state: tensor(0.5535, device='cuda:0')
Mean prior_logit: tensor(-0.0629, device='cuda:0') Std prior_logit: tensor(0.6373, device='cuda:0')
Mean deter_state: tensor(0.0053, device='cuda:0') Std deter_state: tensor(0.5929, device='cuda:0')
Mean prior_logit: tensor(-0.0545, device='cuda:0') Std prior_logit: tensor(0.6472, device='cuda:0')
Mean deter_state: tensor(-0.0132, device='cuda:0') Std deter_state: tensor(0.3785, device='cuda:0')
Mean prior_logit: tensor(-0.1626, device='cuda:0') Std prior_logit: tensor(0.6914, device='cuda:0')
Mean deter_state: tensor(0.0033, device='cuda:0') Std deter_state: tensor(0.5332, device='cuda:0')
Mean prior_logit: tensor(-0.0640, device='cuda:0') Std prior_logit: tensor(0.6308, device='cuda:0')
Mean deter_state: tensor(0.0020, device='cuda:0') Std deter_state: tensor(0.5179, device='cuda:0')
Mean prior_logit: tensor(-0.0877, device='cuda:0') Std prior_logit: tensor(0.6156, device='cuda:0')
Mean deter_state: tensor(-0.0110, device='cuda:0') Std deter_state: tensor(0.2526, device='cuda:0')
Mean prior_logit: tensor(-0.1305, device='cuda:0') Std prior_logit: tensor(0.5224, device='cuda:0')
Mean deter_state: tensor(0.0006, device='cuda:0') Std deter_state: tensor(0.5715, device='cuda:0')
Mean prior_logit: tensor(-0.0702, device='cuda:0') Std prior_logit: tensor(0.6341, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.5528, device='cuda:0')
Mean prior_logit: tensor(-0.0780, device='cuda:0') Std prior_logit: tensor(0.6270, device='cuda:0')
Mean deter_state: tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4478, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1053, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6124, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([3.3877e-05, 2.4720e-04, 5.9918e-06, 1.6467e-05, 6.7070e-05, 2.3550e-04,
        2.9642e-04, 1.2806e-04, 2.1391e-04, 4.2078e-05, 4.6168e-05, 9.9867e-01],
       device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.5237, device='cuda:0')
Mean prior_logit: tensor(-0.0683, device='cuda:0') Std prior_logit: tensor(0.6130, device='cuda:0')
Mean deter_state: tensor(0.0073, device='cuda:0') Std deter_state: tensor(0.5801, device='cuda:0')
Mean prior_logit: tensor(-0.0649, device='cuda:0') Std prior_logit: tensor(0.6377, device='cuda:0')
Mean deter_state: tensor(-0.0151, device='cuda:0') Std deter_state: tensor(0.3704, device='cuda:0')
Mean prior_logit: tensor(-0.1746, device='cuda:0') Std prior_logit: tensor(0.7106, device='cuda:0')
Count of actions: (array([ 6, 11]), array([  1, 202]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_11.gif
Eval_AverageReturn : -175.1999969482422
Eval_StdReturn : 147.30567932128906
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 189.5
Train_AverageReturn : -135.53846740722656
Train_StdReturn : 182.18307495117188
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 157.53846740722656
Train_EnvstepsSoFar : 98304.0
TimeSinceStart : 2586.205158472061
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 70.40084915161133
Loss_Value : -0.4758719436824322
Loss_Entropy : 0.011296660383231938
Loss_Representation : -0.6307524263858795
Loss_KL : 3.2114628195762633
Loss_Obs : -1.5588491916656495
Loss_Reward : -2.3196844935417174
Loss_Discount : 0.03631849116645754
Loss_RawKL : 3.201415830850601
mean_target : -7.822408783435821
max_target : -7.652289927005768
min_target : -7.9302367806434635
std_target : 0.10039767399430274
Done logging...

Current epsilon: 0.10124154532793868 at iteration 98304


********** Iteration 12 ************
Mean deter_state: tensor(0.0058, device='cuda:0') Std deter_state: tensor(0.5656, device='cuda:0')
Mean prior_logit: tensor(-0.0616, device='cuda:0') Std prior_logit: tensor(0.6361, device='cuda:0')
Mean deter_state: tensor(-0.0033, device='cuda:0') Std deter_state: tensor(0.5025, device='cuda:0')
Mean prior_logit: tensor(-0.1054, device='cuda:0') Std prior_logit: tensor(0.6261, device='cuda:0')
Mean deter_state: tensor(0.0018, device='cuda:0') Std deter_state: tensor(0.5491, device='cuda:0')
Mean prior_logit: tensor(-0.0847, device='cuda:0') Std prior_logit: tensor(0.6329, device='cuda:0')
Mean deter_state: tensor(-0.0157, device='cuda:0') Std deter_state: tensor(0.3656, device='cuda:0')
Mean prior_logit: tensor(-0.1768, device='cuda:0') Std prior_logit: tensor(0.7188, device='cuda:0')
Mean deter_state: tensor(0.0012, device='cuda:0') Std deter_state: tensor(0.5563, device='cuda:0')
Mean prior_logit: tensor(-0.0808, device='cuda:0') Std prior_logit: tensor(0.6357, device='cuda:0')
Mean deter_state: tensor(-0.0034, device='cuda:0') Std deter_state: tensor(0.3598, device='cuda:0')
Mean prior_logit: tensor(-0.1045, device='cuda:0') Std prior_logit: tensor(0.5749, device='cuda:0')
Mean deter_state: tensor(-0.0151, device='cuda:0') Std deter_state: tensor(0.3640, device='cuda:0')
Mean prior_logit: tensor(-0.1837, device='cuda:0') Std prior_logit: tensor(0.7267, device='cuda:0')
Mean deter_state: tensor(-0.0081, device='cuda:0') Std deter_state: tensor(0.3987, device='cuda:0')
Mean prior_logit: tensor(-0.1442, device='cuda:0') Std prior_logit: tensor(0.6402, device='cuda:0')
Mean deter_state: tensor(0.0023, device='cuda:0') Std deter_state: tensor(0.5145, device='cuda:0')
Mean prior_logit: tensor(-0.0673, device='cuda:0') Std prior_logit: tensor(0.6133, device='cuda:0')
Mean deter_state: tensor(-0.0159, device='cuda:0') Std deter_state: tensor(0.3559, device='cuda:0')
Mean prior_logit: tensor(-0.1663, device='cuda:0') Std prior_logit: tensor(0.6936, device='cuda:0')
Mean deter_state: tensor(-0.0059, device='cuda:0') Std deter_state: tensor(0.3749, device='cuda:0')
Mean prior_logit: tensor(-0.1021, device='cuda:0') Std prior_logit: tensor(0.5833, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.5687, device='cuda:0')
Mean prior_logit: tensor(-0.0759, device='cuda:0') Std prior_logit: tensor(0.6345, device='cuda:0')
Mean deter_state: tensor(0.0001, device='cuda:0') Std deter_state: tensor(0.5055, device='cuda:0')
Mean prior_logit: tensor(-0.0921, device='cuda:0') Std prior_logit: tensor(0.6187, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.4800, device='cuda:0')
Mean prior_logit: tensor(-0.0742, device='cuda:0') Std prior_logit: tensor(0.6112, device='cuda:0')
Mean deter_state: tensor(-0.0030, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4928, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1064, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6481, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0049, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4599, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1068, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6386, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4867, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1055, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6409, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([1.1087e-04, 8.2241e-04, 1.6764e-05, 4.8594e-05, 2.3960e-04, 9.9456e-04,
        1.1955e-03, 4.1011e-04, 1.1140e-03, 1.4117e-04, 1.4104e-04, 9.9477e-01],
       device='cuda:0')
Count of actions: (array([ 1,  5,  6,  7,  8, 11]), array([  1,   1,   1,   1,   1, 295]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_12.gif
Eval_AverageReturn : -83.4000015258789
Eval_StdReturn : 153.36831665039062
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 129.8000030517578
Train_AverageReturn : -167.04347229003906
Train_StdReturn : 176.89102172851562
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 178.0869598388672
Train_EnvstepsSoFar : 106496.0
TimeSinceStart : 2797.4150965213776
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 74.79924125671387
Loss_Value : -0.5675162307918071
Loss_Entropy : 0.039713535364717244
Loss_Representation : -0.889428973197937
Loss_KL : 3.115896534919739
Loss_Obs : -1.574026393890381
Loss_Reward : -2.4644474416971205
Loss_Discount : 0.033148327143862844
Loss_RawKL : 3.10176500082016
mean_target : -8.311390042304993
max_target : -8.154189682006836
min_target : -8.409291863441467
std_target : 0.09271490052342415
Done logging...

Current epsilon: 0.09054828524893951 at iteration 106496


********** Iteration 13 ************
Mean deter_state: tensor(0.0009, device='cuda:0') Std deter_state: tensor(0.4041, device='cuda:0')
Mean prior_logit: tensor(-0.0944, device='cuda:0') Std prior_logit: tensor(0.5999, device='cuda:0')
Mean deter_state: tensor(-0.0123, device='cuda:0') Std deter_state: tensor(0.3579, device='cuda:0')
Mean prior_logit: tensor(-0.1648, device='cuda:0') Std prior_logit: tensor(0.6917, device='cuda:0')
Mean deter_state: tensor(-0.0118, device='cuda:0') Std deter_state: tensor(0.3922, device='cuda:0')
Mean prior_logit: tensor(-0.1660, device='cuda:0') Std prior_logit: tensor(0.6989, device='cuda:0')
Mean deter_state: tensor(0.0073, device='cuda:0') Std deter_state: tensor(0.6438, device='cuda:0')
Mean prior_logit: tensor(-0.0479, device='cuda:0') Std prior_logit: tensor(0.6952, device='cuda:0')
Mean deter_state: tensor(0.0047, device='cuda:0') Std deter_state: tensor(0.5991, device='cuda:0')
Mean prior_logit: tensor(-0.0692, device='cuda:0') Std prior_logit: tensor(0.6660, device='cuda:0')
Mean deter_state: tensor(0.0009, device='cuda:0') Std deter_state: tensor(0.5445, device='cuda:0')
Mean prior_logit: tensor(-0.0949, device='cuda:0') Std prior_logit: tensor(0.6463, device='cuda:0')
Mean deter_state: tensor(0.0046, device='cuda:0') Std deter_state: tensor(0.5972, device='cuda:0')
Mean prior_logit: tensor(-0.0674, device='cuda:0') Std prior_logit: tensor(0.6642, device='cuda:0')
Mean deter_state: tensor(-0.0052, device='cuda:0') Std deter_state: tensor(0.1292, device='cuda:0')
Mean prior_logit: tensor(-0.0729, device='cuda:0') Std prior_logit: tensor(0.2946, device='cuda:0')
Mean deter_state: tensor(0.0063, device='cuda:0') Std deter_state: tensor(0.5827, device='cuda:0')
Mean prior_logit: tensor(-0.0769, device='cuda:0') Std prior_logit: tensor(0.6586, device='cuda:0')
Mean deter_state: tensor(0.0061, device='cuda:0') Std deter_state: tensor(0.6240, device='cuda:0')
Mean prior_logit: tensor(-0.0669, device='cuda:0') Std prior_logit: tensor(0.6833, device='cuda:0')
Mean deter_state: tensor(-0.0109, device='cuda:0') Std deter_state: tensor(0.2148, device='cuda:0')
Mean prior_logit: tensor(-0.1182, device='cuda:0') Std prior_logit: tensor(0.4584, device='cuda:0')
Mean deter_state: tensor(-0.0038, device='cuda:0') Std deter_state: tensor(0.4673, device='cuda:0')
Mean prior_logit: tensor(-0.1190, device='cuda:0') Std prior_logit: tensor(0.6240, device='cuda:0')
Mean deter_state: tensor(-0.0121, device='cuda:0') Std deter_state: tensor(0.3553, device='cuda:0')
Mean prior_logit: tensor(-0.1716, device='cuda:0') Std prior_logit: tensor(0.7068, device='cuda:0')
Mean deter_state: tensor(-0.0101, device='cuda:0') Std deter_state: tensor(0.4320, device='cuda:0')
Mean prior_logit: tensor(-0.1476, device='cuda:0') Std prior_logit: tensor(0.6685, device='cuda:0')
Mean deter_state: tensor(-0.0142, device='cuda:0') Std deter_state: tensor(0.3660, device='cuda:0')
Mean prior_logit: tensor(-0.1626, device='cuda:0') Std prior_logit: tensor(0.6890, device='cuda:0')
Mean deter_state: tensor(-0.0039, device='cuda:0') Std deter_state: tensor(0.5643, device='cuda:0')
Mean prior_logit: tensor(-0.0807, device='cuda:0') Std prior_logit: tensor(0.6394, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4977, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1059, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6472, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-7.0487e-05, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5307, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0951, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6636, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4963, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1000, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6490, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5125, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1000, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6682, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4995, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1048, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6475, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0005, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5250, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0938, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6639, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4865, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1057, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6439, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0021, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4909, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1033, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6604, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0218, 0.0317, 0.0070, 0.0094, 0.0333, 0.1232, 0.0734, 0.0253, 0.1200,
        0.0178, 0.0214, 0.5157], device='cuda:0')
Mean deter_state: tensor(-0.0071, device='cuda:0') Std deter_state: tensor(0.4609, device='cuda:0')
Mean prior_logit: tensor(-0.1472, device='cuda:0') Std prior_logit: tensor(0.6742, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.5955, device='cuda:0')
Mean prior_logit: tensor(-0.0782, device='cuda:0') Std prior_logit: tensor(0.6817, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10]), array([2, 2, 1, 1, 3, 7, 3, 2, 3, 1]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_13.gif
Eval_AverageReturn : -107.80000305175781
Eval_StdReturn : 230.6953887939453
Eval_MaxReturn : 95.0
Eval_MinReturn : -400.0
Eval_AverageEpLen : 130.89999389648438
Train_AverageReturn : -153.3541717529297
Train_StdReturn : 186.8844757080078
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 170.6666717529297
Train_EnvstepsSoFar : 114688.0
TimeSinceStart : 3002.8995814323425
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 78.48899765014649
Loss_Value : -0.6819918930530549
Loss_Entropy : 1.3621655674651265
Loss_Representation : -0.9419892370700836
Loss_KL : 3.1431815683841706
Loss_Obs : -1.6006544530391693
Loss_Reward : -2.515773171186447
Loss_Discount : 0.03125682733952999
Loss_RawKL : 3.1401146352291107
mean_target : -8.734591031074524
max_target : -8.582606291770935
min_target : -8.830357813835144
std_target : 0.09009723607450723
Done logging...

Current epsilon: 0.08208653107760414 at iteration 114688


********** Iteration 14 ************
Mean deter_state: tensor(0.0007, device='cuda:0') Std deter_state: tensor(0.5706, device='cuda:0')
Mean prior_logit: tensor(-0.0920, device='cuda:0') Std prior_logit: tensor(0.6618, device='cuda:0')
Mean deter_state: tensor(0.0067, device='cuda:0') Std deter_state: tensor(0.6240, device='cuda:0')
Mean prior_logit: tensor(-0.0651, device='cuda:0') Std prior_logit: tensor(0.7142, device='cuda:0')
Mean deter_state: tensor(0.0039, device='cuda:0') Std deter_state: tensor(0.6081, device='cuda:0')
Mean prior_logit: tensor(-0.0720, device='cuda:0') Std prior_logit: tensor(0.6997, device='cuda:0')
Mean deter_state: tensor(0.0068, device='cuda:0') Std deter_state: tensor(0.6285, device='cuda:0')
Mean prior_logit: tensor(-0.0730, device='cuda:0') Std prior_logit: tensor(0.7092, device='cuda:0')
Mean deter_state: tensor(0.0048, device='cuda:0') Std deter_state: tensor(0.6046, device='cuda:0')
Mean prior_logit: tensor(-0.0815, device='cuda:0') Std prior_logit: tensor(0.6988, device='cuda:0')
Mean deter_state: tensor(0.0063, device='cuda:0') Std deter_state: tensor(0.6241, device='cuda:0')
Mean prior_logit: tensor(-0.0721, device='cuda:0') Std prior_logit: tensor(0.6976, device='cuda:0')
Mean deter_state: tensor(-0.0150, device='cuda:0') Std deter_state: tensor(0.3976, device='cuda:0')
Mean prior_logit: tensor(-0.1782, device='cuda:0') Std prior_logit: tensor(0.7359, device='cuda:0')
Mean deter_state: tensor(0.0075, device='cuda:0') Std deter_state: tensor(0.6351, device='cuda:0')
Mean prior_logit: tensor(-0.0556, device='cuda:0') Std prior_logit: tensor(0.7380, device='cuda:0')
Mean deter_state: tensor(-0.0103, device='cuda:0') Std deter_state: tensor(0.4333, device='cuda:0')
Mean prior_logit: tensor(-0.1685, device='cuda:0') Std prior_logit: tensor(0.7215, device='cuda:0')
Mean deter_state: tensor(0.0037, device='cuda:0') Std deter_state: tensor(0.5746, device='cuda:0')
Mean prior_logit: tensor(-0.0688, device='cuda:0') Std prior_logit: tensor(0.6936, device='cuda:0')
Mean deter_state: tensor(0.0038, device='cuda:0') Std deter_state: tensor(0.5937, device='cuda:0')
Mean prior_logit: tensor(-0.0854, device='cuda:0') Std prior_logit: tensor(0.6841, device='cuda:0')
Mean deter_state: tensor(0.0068, device='cuda:0') Std deter_state: tensor(0.6278, device='cuda:0')
Mean prior_logit: tensor(-0.0652, device='cuda:0') Std prior_logit: tensor(0.7093, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.5834, device='cuda:0')
Mean prior_logit: tensor(-0.0852, device='cuda:0') Std prior_logit: tensor(0.6834, device='cuda:0')
Mean deter_state: tensor(0.0043, device='cuda:0') Std deter_state: tensor(0.5379, device='cuda:0')
Mean prior_logit: tensor(-0.0728, device='cuda:0') Std prior_logit: tensor(0.6862, device='cuda:0')
Mean deter_state: tensor(0.0012, device='cuda:0') Std deter_state: tensor(0.4638, device='cuda:0')
Mean prior_logit: tensor(-0.0879, device='cuda:0') Std prior_logit: tensor(0.6533, device='cuda:0')
Mean deter_state: tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5270, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1072, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6929, device='cuda:0', grad_fn=<StdBackward0>)
Imagined rewards:  tensor([-0.0948, -0.0949, -0.1017, -0.1065, -0.1058, -0.1041, -0.1048, -0.1079,
        -0.1048, -0.1046], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-9.0822, -9.1754, -9.1965, -9.1789, -9.1394, -9.0973, -9.0542, -9.0070,
        -8.9517], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-9.0822, -9.1754, -9.1965, -9.1789, -9.1394, -9.0973, -9.0542, -9.0070,
        -8.9517], device='cuda:0', grad_fn=<SelectBackward0>)
Mean deter_state: tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4872, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1109, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6480, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0023, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4684, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0946, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6093, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4985, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0825, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5871, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4812, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0823, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5521, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0494, 0.0259, 0.0109, 0.0221, 0.0343, 0.3710, 0.0798, 0.0272, 0.0538,
        0.0172, 0.2739, 0.0344], device='cuda:0')
Mean deter_state: tensor(0.0064, device='cuda:0') Std deter_state: tensor(0.5778, device='cuda:0')
Mean prior_logit: tensor(-0.0399, device='cuda:0') Std prior_logit: tensor(0.5993, device='cuda:0')
Mean deter_state: tensor(0.0030, device='cuda:0') Std deter_state: tensor(0.5258, device='cuda:0')
Mean prior_logit: tensor(-0.0599, device='cuda:0') Std prior_logit: tensor(0.5764, device='cuda:0')
Mean deter_state: tensor(-0.0036, device='cuda:0') Std deter_state: tensor(0.4696, device='cuda:0')
Mean prior_logit: tensor(-0.0845, device='cuda:0') Std prior_logit: tensor(0.5516, device='cuda:0')
Mean deter_state: tensor(-0.0155, device='cuda:0') Std deter_state: tensor(0.3088, device='cuda:0')
Mean prior_logit: tensor(-0.1464, device='cuda:0') Std prior_logit: tensor(0.6068, device='cuda:0')
Mean deter_state: tensor(-0.0135, device='cuda:0') Std deter_state: tensor(0.3479, device='cuda:0')
Mean prior_logit: tensor(-0.1475, device='cuda:0') Std prior_logit: tensor(0.6230, device='cuda:0')
Count of actions: (array([ 1,  4,  7, 10]), array([1, 1, 1, 4]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_14.gif
Eval_AverageReturn : -253.5
Eval_StdReturn : 174.4403839111328
Eval_MaxReturn : 94.0
Eval_MinReturn : -405.0
Eval_AverageEpLen : 228.5
Train_AverageReturn : -204.53488159179688
Train_StdReturn : 217.2292022705078
Train_MaxReturn : 95.0
Train_MinReturn : -390.0
Train_AverageEpLen : 190.51162719726562
Train_EnvstepsSoFar : 122880.0
TimeSinceStart : 3222.5618579387665
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 80.84530925750732
Loss_Value : -0.5617666400969028
Loss_Entropy : 1.7175663262605667
Loss_Representation : 3.8046907633543015
Loss_KL : 3.202016055583954
Loss_Obs : -0.5834095660597086
Loss_Reward : 1.1507345296442508
Loss_Discount : 0.03534975098446012
Loss_RawKL : 3.017121767997742
mean_target : -8.999959063529968
max_target : -8.849499988555909
min_target : -9.105395102500916
std_target : 0.0922216571867466
Done logging...

Current epsilon: 0.07539060456621857 at iteration 122880


********** Iteration 15 ************
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.4691, device='cuda:0')
Mean prior_logit: tensor(-0.0770, device='cuda:0') Std prior_logit: tensor(0.5531, device='cuda:0')
Mean deter_state: tensor(-0.0083, device='cuda:0') Std deter_state: tensor(0.4907, device='cuda:0')
Mean prior_logit: tensor(-0.0809, device='cuda:0') Std prior_logit: tensor(0.5214, device='cuda:0')
Mean deter_state: tensor(0.0047, device='cuda:0') Std deter_state: tensor(0.5810, device='cuda:0')
Mean prior_logit: tensor(-0.0474, device='cuda:0') Std prior_logit: tensor(0.5790, device='cuda:0')
Mean deter_state: tensor(-0.0084, device='cuda:0') Std deter_state: tensor(0.3947, device='cuda:0')
Mean prior_logit: tensor(-0.1118, device='cuda:0') Std prior_logit: tensor(0.5499, device='cuda:0')
Mean deter_state: tensor(-0.0161, device='cuda:0') Std deter_state: tensor(0.3411, device='cuda:0')
Mean prior_logit: tensor(-0.1626, device='cuda:0') Std prior_logit: tensor(0.6615, device='cuda:0')
Mean deter_state: tensor(0.0058, device='cuda:0') Std deter_state: tensor(0.5792, device='cuda:0')
Mean prior_logit: tensor(-0.0356, device='cuda:0') Std prior_logit: tensor(0.6344, device='cuda:0')
Mean deter_state: tensor(0.0027, device='cuda:0') Std deter_state: tensor(0.5910, device='cuda:0')
Mean prior_logit: tensor(-0.0393, device='cuda:0') Std prior_logit: tensor(0.6318, device='cuda:0')
Mean deter_state: tensor(-0.0186, device='cuda:0') Std deter_state: tensor(0.3192, device='cuda:0')
Mean prior_logit: tensor(-0.1586, device='cuda:0') Std prior_logit: tensor(0.6413, device='cuda:0')
Mean deter_state: tensor(-0.0062, device='cuda:0') Std deter_state: tensor(0.4830, device='cuda:0')
Mean prior_logit: tensor(-0.0790, device='cuda:0') Std prior_logit: tensor(0.5287, device='cuda:0')
Mean deter_state: tensor(0.0035, device='cuda:0') Std deter_state: tensor(0.5727, device='cuda:0')
Mean prior_logit: tensor(-0.0490, device='cuda:0') Std prior_logit: tensor(0.5721, device='cuda:0')
Mean deter_state: tensor(-0.0162, device='cuda:0') Std deter_state: tensor(0.3297, device='cuda:0')
Mean prior_logit: tensor(-0.1606, device='cuda:0') Std prior_logit: tensor(0.6555, device='cuda:0')
Mean deter_state: tensor(-0.0073, device='cuda:0') Std deter_state: tensor(0.4207, device='cuda:0')
Mean prior_logit: tensor(-0.1002, device='cuda:0') Std prior_logit: tensor(0.5331, device='cuda:0')
Mean deter_state: tensor(0.0028, device='cuda:0') Std deter_state: tensor(0.5795, device='cuda:0')
Mean prior_logit: tensor(-0.0435, device='cuda:0') Std prior_logit: tensor(0.5827, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.5199, device='cuda:0')
Mean prior_logit: tensor(-0.0684, device='cuda:0') Std prior_logit: tensor(0.5452, device='cuda:0')
Mean deter_state: tensor(-0.0150, device='cuda:0') Std deter_state: tensor(0.3809, device='cuda:0')
Mean prior_logit: tensor(-0.1475, device='cuda:0') Std prior_logit: tensor(0.6177, device='cuda:0')
Mean deter_state: tensor(0.0046, device='cuda:0') Std deter_state: tensor(0.5822, device='cuda:0')
Mean prior_logit: tensor(-0.0460, device='cuda:0') Std prior_logit: tensor(0.5854, device='cuda:0')
Mean deter_state: tensor(-0.0072, device='cuda:0') Std deter_state: tensor(0.4179, device='cuda:0')
Mean prior_logit: tensor(-0.0971, device='cuda:0') Std prior_logit: tensor(0.5168, device='cuda:0')
Mean deter_state: tensor(0.0050, device='cuda:0') Std deter_state: tensor(0.5508, device='cuda:0')
Mean prior_logit: tensor(-0.0491, device='cuda:0') Std prior_logit: tensor(0.5853, device='cuda:0')
Mean deter_state: tensor(0.0056, device='cuda:0') Std deter_state: tensor(0.5883, device='cuda:0')
Mean prior_logit: tensor(-0.0430, device='cuda:0') Std prior_logit: tensor(0.5741, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.0399, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0147, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0886, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0008, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5031, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0601, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5532, device='cuda:0', grad_fn=<StdBackward0>)
Imagined rewards:  tensor([-0.0906, -0.1016, -0.1011, -0.1029, -0.1050, -0.1025, -0.1004, -0.0997,
        -0.1041, -0.1011], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-8.5565, -8.6644, -8.6646, -8.6388, -8.6024, -8.5653, -8.5244, -8.4910,
        -8.4639], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-8.5565, -8.6644, -8.6646, -8.6388, -8.6024, -8.5653, -8.5244, -8.4910,
        -8.4639], device='cuda:0', grad_fn=<SelectBackward0>)
Current action distribution:
tensor([0.0096, 0.0018, 0.0010, 0.0038, 0.0030, 0.0824, 0.0062, 0.0022, 0.0032,
        0.0012, 0.8836, 0.0022], device='cuda:0')
Mean deter_state: tensor(0.0053, device='cuda:0') Std deter_state: tensor(0.5792, device='cuda:0')
Mean prior_logit: tensor(-0.0229, device='cuda:0') Std prior_logit: tensor(0.5262, device='cuda:0')
Mean deter_state: tensor(0.0045, device='cuda:0') Std deter_state: tensor(0.5299, device='cuda:0')
Mean prior_logit: tensor(-0.0217, device='cuda:0') Std prior_logit: tensor(0.6068, device='cuda:0')
Count of actions: (array([ 4,  5,  6, 10]), array([  1,   8,   1, 109]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_15.gif
Eval_AverageReturn : -125.80000305175781
Eval_StdReturn : 202.0469207763672
Eval_MaxReturn : 95.0
Eval_MinReturn : -410.0
Eval_AverageEpLen : 146.5
Train_AverageReturn : -163.31915283203125
Train_StdReturn : 195.80287170410156
Train_MaxReturn : 95.0
Train_MinReturn : -405.0
Train_AverageEpLen : 174.29786682128906
Train_EnvstepsSoFar : 131072.0
TimeSinceStart : 3432.384147644043
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 77.63497867584229
Loss_Value : -0.5985333599150181
Loss_Entropy : 0.47522718757390975
Loss_Representation : 0.515366867184639
Loss_KL : 3.0302269756793976
Loss_Obs : -0.8058133628219366
Loss_Reward : -1.7410599514609202
Loss_Discount : 0.03201317922212184
Loss_RawKL : 2.753773993253708
mean_target : -8.63073651790619
max_target : -8.493656539916993
min_target : -8.7221431016922
std_target : 0.0828182129189372
Done logging...

Current epsilon: 0.07009200678873188 at iteration 131072


********** Iteration 16 ************
Mean deter_state: tensor(0.0034, device='cuda:0') Std deter_state: tensor(0.5731, device='cuda:0')
Mean prior_logit: tensor(-0.0231, device='cuda:0') Std prior_logit: tensor(0.5184, device='cuda:0')
Mean deter_state: tensor(-0.0138, device='cuda:0') Std deter_state: tensor(0.3491, device='cuda:0')
Mean prior_logit: tensor(-0.1333, device='cuda:0') Std prior_logit: tensor(0.5637, device='cuda:0')
Mean deter_state: tensor(-0.0038, device='cuda:0') Std deter_state: tensor(0.4725, device='cuda:0')
Mean prior_logit: tensor(-0.0616, device='cuda:0') Std prior_logit: tensor(0.4646, device='cuda:0')
Mean deter_state: tensor(-0.0053, device='cuda:0') Std deter_state: tensor(0.4611, device='cuda:0')
Mean prior_logit: tensor(-0.0666, device='cuda:0') Std prior_logit: tensor(0.4406, device='cuda:0')
Mean deter_state: tensor(-0.0033, device='cuda:0') Std deter_state: tensor(0.4722, device='cuda:0')
Mean prior_logit: tensor(-0.0600, device='cuda:0') Std prior_logit: tensor(0.4459, device='cuda:0')
Mean deter_state: tensor(0.0069, device='cuda:0') Std deter_state: tensor(0.5673, device='cuda:0')
Mean prior_logit: tensor(-0.0249, device='cuda:0') Std prior_logit: tensor(0.5174, device='cuda:0')
Mean deter_state: tensor(0.0044, device='cuda:0') Std deter_state: tensor(0.5491, device='cuda:0')
Mean prior_logit: tensor(-0.0339, device='cuda:0') Std prior_logit: tensor(0.4855, device='cuda:0')
Mean deter_state: tensor(-0.0068, device='cuda:0') Std deter_state: tensor(0.4384, device='cuda:0')
Mean prior_logit: tensor(-0.0777, device='cuda:0') Std prior_logit: tensor(0.4343, device='cuda:0')
Mean deter_state: tensor(0.0018, device='cuda:0') Std deter_state: tensor(0.5810, device='cuda:0')
Mean prior_logit: tensor(-0.0228, device='cuda:0') Std prior_logit: tensor(0.5176, device='cuda:0')
Mean deter_state: tensor(0.0023, device='cuda:0') Std deter_state: tensor(0.5210, device='cuda:0')
Mean prior_logit: tensor(-0.0357, device='cuda:0') Std prior_logit: tensor(0.4835, device='cuda:0')
Mean deter_state: tensor(-0.0005, device='cuda:0') Std deter_state: tensor(0.4839, device='cuda:0')
Mean prior_logit: tensor(-0.0448, device='cuda:0') Std prior_logit: tensor(0.4612, device='cuda:0')
Mean deter_state: tensor(-0.0015, device='cuda:0') Std deter_state: tensor(0.5063, device='cuda:0')
Mean prior_logit: tensor(-0.0440, device='cuda:0') Std prior_logit: tensor(0.4603, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5024, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0604, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5550, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4966, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0766, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6035, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0152, 0.0016, 0.0006, 0.0040, 0.0024, 0.3521, 0.0082, 0.0024, 0.0035,
        0.0008, 0.6070, 0.0021], device='cuda:0')
Mean deter_state: tensor(0.0078, device='cuda:0') Std deter_state: tensor(0.5633, device='cuda:0')
Mean prior_logit: tensor(-0.0503, device='cuda:0') Std prior_logit: tensor(0.6018, device='cuda:0')
Mean deter_state: tensor(0.0081, device='cuda:0') Std deter_state: tensor(0.6153, device='cuda:0')
Mean prior_logit: tensor(-0.0367, device='cuda:0') Std prior_logit: tensor(0.6395, device='cuda:0')
Mean deter_state: tensor(0.0004, device='cuda:0') Std deter_state: tensor(0.4637, device='cuda:0')
Mean prior_logit: tensor(-0.0908, device='cuda:0') Std prior_logit: tensor(0.5257, device='cuda:0')
Count of actions: (array([ 0,  3,  4,  5,  6,  7, 10]), array([ 7,  1,  1, 68,  3,  1, 56]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_16.gif
Eval_AverageReturn : -201.6999969482422
Eval_StdReturn : 158.5869140625
Eval_MaxReturn : 93.0
Eval_MinReturn : -390.0
Eval_AverageEpLen : 212.89999389648438
Train_AverageReturn : -176.26666259765625
Train_StdReturn : 178.92002868652344
Train_MaxReturn : 95.0
Train_MinReturn : -410.0
Train_AverageEpLen : 182.04444885253906
Train_EnvstepsSoFar : 139264.0
TimeSinceStart : 3651.208873271942
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 81.88511295318604
Loss_Value : -0.8672736749053002
Loss_Entropy : 0.7775913178920746
Loss_Representation : -0.42386520504951475
Loss_KL : 3.4347229301929474
Loss_Obs : -1.2656829357147217
Loss_Reward : -2.6262541592121122
Loss_Discount : 0.03334898971952498
Loss_RawKL : 3.434722828865051
mean_target : -9.106044149398803
max_target : -8.974426555633546
min_target : -9.191628289222717
std_target : 0.0785993156954646
Done logging...

Current epsilon: 0.06589913842916303 at iteration 139264


********** Iteration 17 ************
Mean deter_state: tensor(-0.0133, device='cuda:0') Std deter_state: tensor(0.3785, device='cuda:0')
Mean prior_logit: tensor(-0.1345, device='cuda:0') Std prior_logit: tensor(0.5773, device='cuda:0')
Mean deter_state: tensor(0.0081, device='cuda:0') Std deter_state: tensor(0.6108, device='cuda:0')
Mean prior_logit: tensor(-0.0401, device='cuda:0') Std prior_logit: tensor(0.6395, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0') Std deter_state: tensor(0.5528, device='cuda:0')
Mean prior_logit: tensor(-0.0583, device='cuda:0') Std prior_logit: tensor(0.5666, device='cuda:0')
Mean deter_state: tensor(-0.0013, device='cuda:0') Std deter_state: tensor(0.5315, device='cuda:0')
Mean prior_logit: tensor(-0.0695, device='cuda:0') Std prior_logit: tensor(0.5434, device='cuda:0')
Mean deter_state: tensor(0.0082, device='cuda:0') Std deter_state: tensor(0.6334, device='cuda:0')
Mean prior_logit: tensor(-0.0359, device='cuda:0') Std prior_logit: tensor(0.6355, device='cuda:0')
Mean deter_state: tensor(0.0079, device='cuda:0') Std deter_state: tensor(0.6145, device='cuda:0')
Mean prior_logit: tensor(-0.0414, device='cuda:0') Std prior_logit: tensor(0.6116, device='cuda:0')
Mean deter_state: tensor(0.0054, device='cuda:0') Std deter_state: tensor(0.5765, device='cuda:0')
Mean prior_logit: tensor(-0.0398, device='cuda:0') Std prior_logit: tensor(0.6523, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0') Std deter_state: tensor(0.5302, device='cuda:0')
Mean prior_logit: tensor(-0.0716, device='cuda:0') Std prior_logit: tensor(0.5565, device='cuda:0')
Mean deter_state: tensor(-0.0166, device='cuda:0') Std deter_state: tensor(0.3064, device='cuda:0')
Mean prior_logit: tensor(-0.1510, device='cuda:0') Std prior_logit: tensor(0.6204, device='cuda:0')
Mean deter_state: tensor(0.0002, device='cuda:0') Std deter_state: tensor(0.4786, device='cuda:0')
Mean prior_logit: tensor(-0.0640, device='cuda:0') Std prior_logit: tensor(0.5761, device='cuda:0')
Mean deter_state: tensor(0.0063, device='cuda:0') Std deter_state: tensor(0.6040, device='cuda:0')
Mean prior_logit: tensor(-0.0408, device='cuda:0') Std prior_logit: tensor(0.6191, device='cuda:0')
Mean deter_state: tensor(0.0050, device='cuda:0') Std deter_state: tensor(0.5547, device='cuda:0')
Mean prior_logit: tensor(-0.0523, device='cuda:0') Std prior_logit: tensor(0.5779, device='cuda:0')
Mean deter_state: tensor(0.0078, device='cuda:0') Std deter_state: tensor(0.6339, device='cuda:0')
Mean prior_logit: tensor(-0.0367, device='cuda:0') Std prior_logit: tensor(0.6412, device='cuda:0')
Mean deter_state: tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5464, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0557, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6011, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4817, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0875, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5824, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5682, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0560, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5965, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4921, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0803, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5640, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0012, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4879, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0830, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5621, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0071, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4365, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1089, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6089, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0036, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4359, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0966, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6011, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0047, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4676, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1024, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5955, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0464, 0.0044, 0.0015, 0.0105, 0.0068, 0.5476, 0.0286, 0.0071, 0.0098,
        0.0021, 0.3300, 0.0051], device='cuda:0')
Mean deter_state: tensor(0.0072, device='cuda:0') Std deter_state: tensor(0.6100, device='cuda:0')
Mean prior_logit: tensor(-0.0515, device='cuda:0') Std prior_logit: tensor(0.6392, device='cuda:0')
Mean deter_state: tensor(-0.0008, device='cuda:0') Std deter_state: tensor(0.4934, device='cuda:0')
Mean prior_logit: tensor(-0.0875, device='cuda:0') Std prior_logit: tensor(0.5721, device='cuda:0')
Mean deter_state: tensor(0.0015, device='cuda:0') Std deter_state: tensor(0.5277, device='cuda:0')
Mean prior_logit: tensor(-0.0775, device='cuda:0') Std prior_logit: tensor(0.5711, device='cuda:0')
Mean deter_state: tensor(-0.0152, device='cuda:0') Std deter_state: tensor(0.3154, device='cuda:0')
Mean prior_logit: tensor(-0.1500, device='cuda:0') Std prior_logit: tensor(0.6260, device='cuda:0')
Mean deter_state: tensor(-0.0052, device='cuda:0') Std deter_state: tensor(0.4480, device='cuda:0')
Mean prior_logit: tensor(-0.1032, device='cuda:0') Std prior_logit: tensor(0.5414, device='cuda:0')
Mean deter_state: tensor(0.0005, device='cuda:0') Std deter_state: tensor(0.5833, device='cuda:0')
Mean prior_logit: tensor(-0.0641, device='cuda:0') Std prior_logit: tensor(0.6028, device='cuda:0')
Mean deter_state: tensor(0.0041, device='cuda:0') Std deter_state: tensor(0.5826, device='cuda:0')
Mean prior_logit: tensor(-0.0476, device='cuda:0') Std prior_logit: tensor(0.6529, device='cuda:0')
Count of actions: (array([ 0,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 20,   4,   2, 172,  12,   1,   4,   1,  83,   1]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_17.gif
Eval_AverageReturn : -237.89999389648438
Eval_StdReturn : 158.79638671875
Eval_MaxReturn : 95.0
Eval_MinReturn : -385.0
Eval_AverageEpLen : 228.89999389648438
Train_AverageReturn : -185.27906799316406
Train_StdReturn : 191.69540405273438
Train_MaxReturn : 95.0
Train_MinReturn : -390.0
Train_AverageEpLen : 190.51162719726562
Train_EnvstepsSoFar : 147456.0
TimeSinceStart : 3876.7809154987335
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 85.0224594116211
Loss_Value : -0.8241985827684403
Loss_Entropy : 1.1595753848552703
Loss_Representation : -0.952611780166626
Loss_KL : 3.0072252452373505
Loss_Obs : -1.4302261620759964
Loss_Reward : -2.5634428679943086
Loss_Discount : 0.03383202264085412
Loss_RawKL : 2.8709171414375305
mean_target : -9.458475160598756
max_target : -9.330762386322021
min_target : -9.53887665271759
std_target : 0.07492377758026122
Done logging...

Current epsilon: 0.06258125210924455 at iteration 147456


********** Iteration 18 ************
Mean deter_state: tensor(-0.0148, device='cuda:0') Std deter_state: tensor(0.3024, device='cuda:0')
Mean prior_logit: tensor(-0.1455, device='cuda:0') Std prior_logit: tensor(0.5912, device='cuda:0')
Mean deter_state: tensor(0.0037, device='cuda:0') Std deter_state: tensor(0.5425, device='cuda:0')
Mean prior_logit: tensor(-0.0674, device='cuda:0') Std prior_logit: tensor(0.5907, device='cuda:0')
Mean deter_state: tensor(0.0042, device='cuda:0') Std deter_state: tensor(0.5632, device='cuda:0')
Mean prior_logit: tensor(-0.0532, device='cuda:0') Std prior_logit: tensor(0.6369, device='cuda:0')
Mean deter_state: tensor(0.0068, device='cuda:0') Std deter_state: tensor(0.5769, device='cuda:0')
Mean prior_logit: tensor(-0.0464, device='cuda:0') Std prior_logit: tensor(0.6606, device='cuda:0')
Mean deter_state: tensor(-0.0110, device='cuda:0') Std deter_state: tensor(0.3116, device='cuda:0')
Mean prior_logit: tensor(-0.1320, device='cuda:0') Std prior_logit: tensor(0.5959, device='cuda:0')
Mean deter_state: tensor(-0.0029, device='cuda:0') Std deter_state: tensor(0.4703, device='cuda:0')
Mean prior_logit: tensor(-0.0886, device='cuda:0') Std prior_logit: tensor(0.5768, device='cuda:0')
Mean deter_state: tensor(-0.0148, device='cuda:0') Std deter_state: tensor(0.3302, device='cuda:0')
Mean prior_logit: tensor(-0.1475, device='cuda:0') Std prior_logit: tensor(0.5912, device='cuda:0')
Mean deter_state: tensor(0.0016, device='cuda:0') Std deter_state: tensor(0.5540, device='cuda:0')
Mean prior_logit: tensor(-0.0627, device='cuda:0') Std prior_logit: tensor(0.6043, device='cuda:0')
Mean deter_state: tensor(0.0105, device='cuda:0') Std deter_state: tensor(0.5844, device='cuda:0')
Mean prior_logit: tensor(-0.0438, device='cuda:0') Std prior_logit: tensor(0.6679, device='cuda:0')
Mean deter_state: tensor(0.0074, device='cuda:0') Std deter_state: tensor(0.5752, device='cuda:0')
Mean prior_logit: tensor(-0.0581, device='cuda:0') Std prior_logit: tensor(0.6047, device='cuda:0')
Mean deter_state: tensor(-0.0167, device='cuda:0') Std deter_state: tensor(0.3097, device='cuda:0')
Mean prior_logit: tensor(-0.1501, device='cuda:0') Std prior_logit: tensor(0.6197, device='cuda:0')
Mean deter_state: tensor(0.0048, device='cuda:0') Std deter_state: tensor(0.5649, device='cuda:0')
Mean prior_logit: tensor(-0.0521, device='cuda:0') Std prior_logit: tensor(0.6416, device='cuda:0')
Imagined rewards:  tensor([-0.0877, -0.0950, -0.0947, -0.0936, -0.0934, -0.0943, -0.0949, -0.0959,
        -0.0965, -0.1054], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-10.1673, -10.2605, -10.2660, -10.2490, -10.2251, -10.1969, -10.1659,
        -10.1334, -10.0941], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-10.1673, -10.2605, -10.2660, -10.2490, -10.2251, -10.1969, -10.1659,
        -10.1334, -10.0941], device='cuda:0', grad_fn=<SelectBackward0>)
Mean deter_state: tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5274, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1040, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6381, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0582, 0.0076, 0.0022, 0.0149, 0.0129, 0.5283, 0.0658, 0.0135, 0.0199,
        0.0033, 0.2660, 0.0075], device='cuda:0')
Mean deter_state: tensor(0.0059, device='cuda:0') Std deter_state: tensor(0.6151, device='cuda:0')
Mean prior_logit: tensor(-0.0843, device='cuda:0') Std prior_logit: tensor(0.6769, device='cuda:0')
Count of actions: (array([ 0,  3,  4,  5,  6,  7,  8, 10, 11]), array([ 2,  1,  1, 10,  1,  1,  1,  7,  1]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_18.gif
Eval_AverageReturn : -171.3000030517578
Eval_StdReturn : 181.21812438964844
Eval_MaxReturn : 94.0
Eval_MinReturn : -390.0
Eval_AverageEpLen : 196.10000610351562
Train_AverageReturn : -149.4130401611328
Train_StdReturn : 167.063720703125
Train_MaxReturn : 95.0
Train_MinReturn : -390.0
Train_AverageEpLen : 178.0869598388672
Train_EnvstepsSoFar : 155648.0
TimeSinceStart : 4091.0266165733337
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 88.97889270782471
Loss_Value : -0.6528057154268027
Loss_Entropy : 1.3785879760980606
Loss_Representation : 13.629959926009178
Loss_KL : 3.1496461749076845
Loss_Obs : -1.4000385791063308
Loss_Reward : 11.844697415828705
Loss_Discount : 0.03565482734702528
Loss_RawKL : 3.095992374420166
mean_target : -9.900275325775146
max_target : -9.776642656326294
min_target : -9.982702326774596
std_target : 0.07356902733445167
Done logging...

Current epsilon: 0.05995575359895166 at iteration 155648


********** Iteration 19 ************
Mean deter_state: tensor(0.0076, device='cuda:0') Std deter_state: tensor(0.5696, device='cuda:0')
Mean prior_logit: tensor(-0.0751, device='cuda:0') Std prior_logit: tensor(0.6953, device='cuda:0')
Mean deter_state: tensor(-0.0076, device='cuda:0') Std deter_state: tensor(0.3662, device='cuda:0')
Mean prior_logit: tensor(-0.1614, device='cuda:0') Std prior_logit: tensor(0.6884, device='cuda:0')
Mean deter_state: tensor(0.0046, device='cuda:0') Std deter_state: tensor(0.6231, device='cuda:0')
Mean prior_logit: tensor(-0.0929, device='cuda:0') Std prior_logit: tensor(0.6646, device='cuda:0')
Mean deter_state: tensor(-0.0120, device='cuda:0') Std deter_state: tensor(0.3540, device='cuda:0')
Mean prior_logit: tensor(-0.1858, device='cuda:0') Std prior_logit: tensor(0.7419, device='cuda:0')
Mean deter_state: tensor(0.0022, device='cuda:0') Std deter_state: tensor(0.4761, device='cuda:0')
Mean prior_logit: tensor(-0.1080, device='cuda:0') Std prior_logit: tensor(0.6597, device='cuda:0')
Mean deter_state: tensor(0.0035, device='cuda:0') Std deter_state: tensor(0.5878, device='cuda:0')
Mean prior_logit: tensor(-0.1049, device='cuda:0') Std prior_logit: tensor(0.6410, device='cuda:0')
Mean deter_state: tensor(-0.0011, device='cuda:0') Std deter_state: tensor(0.5530, device='cuda:0')
Mean prior_logit: tensor(-0.1276, device='cuda:0') Std prior_logit: tensor(0.6511, device='cuda:0')
Mean deter_state: tensor(0.0064, device='cuda:0') Std deter_state: tensor(0.5951, device='cuda:0')
Mean prior_logit: tensor(-0.0758, device='cuda:0') Std prior_logit: tensor(0.6997, device='cuda:0')
Mean deter_state: tensor(-0.0034, device='cuda:0') Std deter_state: tensor(0.4058, device='cuda:0')
Mean prior_logit: tensor(-0.1223, device='cuda:0') Std prior_logit: tensor(0.6626, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.5576, device='cuda:0')
Mean prior_logit: tensor(-0.1219, device='cuda:0') Std prior_logit: tensor(0.6527, device='cuda:0')
Mean deter_state: tensor(-0.0101, device='cuda:0') Std deter_state: tensor(0.2918, device='cuda:0')
Mean prior_logit: tensor(-0.1571, device='cuda:0') Std prior_logit: tensor(0.6284, device='cuda:0')
Mean deter_state: tensor(0.0077, device='cuda:0') Std deter_state: tensor(0.6244, device='cuda:0')
Mean prior_logit: tensor(-0.0868, device='cuda:0') Std prior_logit: tensor(0.6653, device='cuda:0')
Mean deter_state: tensor(-0.0146, device='cuda:0') Std deter_state: tensor(0.3552, device='cuda:0')
Mean prior_logit: tensor(-0.1865, device='cuda:0') Std prior_logit: tensor(0.7443, device='cuda:0')
Mean deter_state: tensor(0.0060, device='cuda:0') Std deter_state: tensor(0.5626, device='cuda:0')
Mean prior_logit: tensor(-0.0783, device='cuda:0') Std prior_logit: tensor(0.7072, device='cuda:0')
Mean deter_state: tensor(0.0021, device='cuda:0') Std deter_state: tensor(0.5355, device='cuda:0')
Mean prior_logit: tensor(-0.1127, device='cuda:0') Std prior_logit: tensor(0.6416, device='cuda:0')
Mean deter_state: tensor(0.0042, device='cuda:0') Std deter_state: tensor(0.5920, device='cuda:0')
Mean prior_logit: tensor(-0.1011, device='cuda:0') Std prior_logit: tensor(0.6586, device='cuda:0')
Mean deter_state: tensor(-0.0155, device='cuda:0') Std deter_state: tensor(0.3404, device='cuda:0')
Mean prior_logit: tensor(-0.1740, device='cuda:0') Std prior_logit: tensor(0.7075, device='cuda:0')
Mean deter_state: tensor(-0.0148, device='cuda:0') Std deter_state: tensor(0.3822, device='cuda:0')
Mean prior_logit: tensor(-0.1911, device='cuda:0') Std prior_logit: tensor(0.7620, device='cuda:0')
Mean deter_state: tensor(-0.0141, device='cuda:0') Std deter_state: tensor(0.3493, device='cuda:0')
Mean prior_logit: tensor(-0.1873, device='cuda:0') Std prior_logit: tensor(0.7382, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.5726, device='cuda:0')
Mean prior_logit: tensor(-0.1144, device='cuda:0') Std prior_logit: tensor(0.6357, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.5001, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1184, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6491, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0063, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4672, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1439, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6899, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0040, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4803, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1094, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6083, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0719, 0.0161, 0.0039, 0.0229, 0.0280, 0.3064, 0.1877, 0.0292, 0.0659,
        0.0065, 0.2487, 0.0128], device='cuda:0')
Mean deter_state: tensor(0.0035, device='cuda:0') Std deter_state: tensor(0.5996, device='cuda:0')
Mean prior_logit: tensor(-0.0615, device='cuda:0') Std prior_logit: tensor(0.5452, device='cuda:0')
Mean deter_state: tensor(-0.0076, device='cuda:0') Std deter_state: tensor(0.4596, device='cuda:0')
Mean prior_logit: tensor(-0.1264, device='cuda:0') Std prior_logit: tensor(0.5696, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.5989, device='cuda:0')
Mean prior_logit: tensor(-0.0602, device='cuda:0') Std prior_logit: tensor(0.5441, device='cuda:0')
Count of actions: (array([ 0,  1,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([  8,   5,   5,   8,  58, 100,   7,  53,   2,  52,   2]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_19.gif
Eval_AverageReturn : -103.4000015258789
Eval_StdReturn : 230.21389770507812
Eval_MaxReturn : 95.0
Eval_MinReturn : -385.0
Eval_AverageEpLen : 129.0
Train_AverageReturn : -273.3939514160156
Train_StdReturn : 152.71124267578125
Train_MaxReturn : 95.0
Train_MinReturn : -400.0
Train_AverageEpLen : 248.242431640625
Train_EnvstepsSoFar : 163840.0
TimeSinceStart : 4301.814269781113
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 90.84022102355956
Loss_Value : -0.5442475721240043
Loss_Entropy : 1.8208006888628006
Loss_Representation : 9.583473312854768
Loss_KL : 3.64436616897583
Loss_Obs : -1.3598761886358262
Loss_Reward : 7.27172027900815
Loss_Discount : 0.027263027033768594
Loss_RawKL : 3.6422110736370086
mean_target : -10.111542510986329
max_target : -10.030047845840453
min_target : -10.173846650123597
std_target : 0.05232017177622765
Done logging...

Current epsilon: 0.057878153053638345 at iteration 163840


********** Iteration 20 ************
Mean deter_state: tensor(0.0065, device='cuda:0') Std deter_state: tensor(0.5888, device='cuda:0')
Mean prior_logit: tensor(-0.0598, device='cuda:0') Std prior_logit: tensor(0.5385, device='cuda:0')
Mean deter_state: tensor(-0.0028, device='cuda:0') Std deter_state: tensor(0.4181, device='cuda:0')
Mean prior_logit: tensor(-0.0832, device='cuda:0') Std prior_logit: tensor(0.5793, device='cuda:0')
Mean deter_state: tensor(0.0030, device='cuda:0') Std deter_state: tensor(0.4666, device='cuda:0')
Mean prior_logit: tensor(-0.0767, device='cuda:0') Std prior_logit: tensor(0.5822, device='cuda:0')
Mean deter_state: tensor(-0.0111, device='cuda:0') Std deter_state: tensor(0.2416, device='cuda:0')
Mean prior_logit: tensor(-0.1282, device='cuda:0') Std prior_logit: tensor(0.5320, device='cuda:0')
Mean deter_state: tensor(0.0067, device='cuda:0') Std deter_state: tensor(0.5393, device='cuda:0')
Mean prior_logit: tensor(-0.0411, device='cuda:0') Std prior_logit: tensor(0.6181, device='cuda:0')
Mean deter_state: tensor(-0.0120, device='cuda:0') Std deter_state: tensor(0.3478, device='cuda:0')
Mean prior_logit: tensor(-0.1542, device='cuda:0') Std prior_logit: tensor(0.6519, device='cuda:0')
Mean deter_state: tensor(0.0067, device='cuda:0') Std deter_state: tensor(0.5994, device='cuda:0')
Mean prior_logit: tensor(-0.0483, device='cuda:0') Std prior_logit: tensor(0.5792, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.5928, device='cuda:0')
Mean prior_logit: tensor(-0.0647, device='cuda:0') Std prior_logit: tensor(0.5418, device='cuda:0')
Mean deter_state: tensor(0.0032, device='cuda:0') Std deter_state: tensor(0.5589, device='cuda:0')
Mean prior_logit: tensor(-0.0745, device='cuda:0') Std prior_logit: tensor(0.5249, device='cuda:0')
Mean deter_state: tensor(0.0036, device='cuda:0') Std deter_state: tensor(0.5862, device='cuda:0')
Mean prior_logit: tensor(-0.0651, device='cuda:0') Std prior_logit: tensor(0.5403, device='cuda:0')
Mean deter_state: tensor(0.0025, device='cuda:0') Std deter_state: tensor(0.5607, device='cuda:0')
Mean prior_logit: tensor(-0.0788, device='cuda:0') Std prior_logit: tensor(0.5256, device='cuda:0')
Mean deter_state: tensor(0.0066, device='cuda:0') Std deter_state: tensor(0.6048, device='cuda:0')
Mean prior_logit: tensor(-0.0552, device='cuda:0') Std prior_logit: tensor(0.5436, device='cuda:0')
Mean deter_state: tensor(0.0064, device='cuda:0') Std deter_state: tensor(0.6196, device='cuda:0')
Mean prior_logit: tensor(-0.0518, device='cuda:0') Std prior_logit: tensor(0.5638, device='cuda:0')
Mean deter_state: tensor(0.0095, device='cuda:0') Std deter_state: tensor(0.6103, device='cuda:0')
Mean prior_logit: tensor(-0.0448, device='cuda:0') Std prior_logit: tensor(0.5927, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.5844, device='cuda:0')
Mean prior_logit: tensor(-0.0664, device='cuda:0') Std prior_logit: tensor(0.5337, device='cuda:0')
Mean deter_state: tensor(-0.0014, device='cuda:0') Std deter_state: tensor(0.3858, device='cuda:0')
Mean prior_logit: tensor(-0.0832, device='cuda:0') Std prior_logit: tensor(0.5623, device='cuda:0')
Mean deter_state: tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4798, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0805, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5596, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0039, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4412, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0953, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5929, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4685, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0843, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5556, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3129, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0734, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4763, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0161, 0.0117, 0.0011, 0.0067, 0.0124, 0.0942, 0.3233, 0.0183, 0.4561,
        0.0027, 0.0519, 0.0056], device='cuda:0')
Mean deter_state: tensor(0.0041, device='cuda:0') Std deter_state: tensor(0.5472, device='cuda:0')
Mean prior_logit: tensor(-0.0675, device='cuda:0') Std prior_logit: tensor(0.5657, device='cuda:0')
Mean deter_state: tensor(-0.0045, device='cuda:0') Std deter_state: tensor(0.4647, device='cuda:0')
Mean prior_logit: tensor(-0.1004, device='cuda:0') Std prior_logit: tensor(0.5383, device='cuda:0')
Mean deter_state: tensor(-0.0167, device='cuda:0') Std deter_state: tensor(0.3185, device='cuda:0')
Mean prior_logit: tensor(-0.1555, device='cuda:0') Std prior_logit: tensor(0.6389, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0') Std deter_state: tensor(0.3629, device='cuda:0')
Mean prior_logit: tensor(-0.0804, device='cuda:0') Std prior_logit: tensor(0.5717, device='cuda:0')
Count of actions: (array([ 0,  1,  3,  4,  5,  6,  7,  8, 10, 11]), array([  4,   2,   1,   2,  15,  53,   2, 142,   7,   1]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_20.gif
Eval_AverageReturn : -202.5
Eval_StdReturn : 234.8536834716797
Eval_MaxReturn : 95.0
Eval_MinReturn : -400.0
Eval_AverageEpLen : 185.39999389648438
Train_AverageReturn : -164.36734008789062
Train_StdReturn : 225.6195831298828
Train_MaxReturn : 95.0
Train_MinReturn : -390.0
Train_AverageEpLen : 167.1836700439453
Train_EnvstepsSoFar : 172032.0
TimeSinceStart : 4518.697309732437
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 88.79432125091553
Loss_Value : -0.47356991153210404
Loss_Entropy : 1.336076945066452
Loss_Representation : 2.6776178032159805
Loss_KL : 3.2339468121528627
Loss_Obs : -1.3114543914794923
Loss_Reward : 0.7185150971636176
Loss_Discount : 0.036610293621197346
Loss_RawKL : 3.174316430091858
mean_target : -9.879290533065795
max_target : -9.841523480415344
min_target : -9.912813472747803
std_target : 0.026087974244728685
Done logging...

Current epsilon: 0.05623411326120875 at iteration 172032


********** Iteration 21 ************
Mean deter_state: tensor(-0.0123, device='cuda:0') Std deter_state: tensor(0.2445, device='cuda:0')
Mean prior_logit: tensor(-0.1262, device='cuda:0') Std prior_logit: tensor(0.5082, device='cuda:0')
Mean deter_state: tensor(-0.0144, device='cuda:0') Std deter_state: tensor(0.3091, device='cuda:0')
Mean prior_logit: tensor(-0.1573, device='cuda:0') Std prior_logit: tensor(0.6490, device='cuda:0')
Mean deter_state: tensor(-0.0027, device='cuda:0') Std deter_state: tensor(0.4676, device='cuda:0')
Mean prior_logit: tensor(-0.1038, device='cuda:0') Std prior_logit: tensor(0.5372, device='cuda:0')
Mean deter_state: tensor(0.0029, device='cuda:0') Std deter_state: tensor(0.5176, device='cuda:0')
Mean prior_logit: tensor(-0.0837, device='cuda:0') Std prior_logit: tensor(0.5471, device='cuda:0')
Mean deter_state: tensor(-0.0038, device='cuda:0') Std deter_state: tensor(0.3823, device='cuda:0')
Mean prior_logit: tensor(-0.0829, device='cuda:0') Std prior_logit: tensor(0.5875, device='cuda:0')
Mean deter_state: tensor(0.0047, device='cuda:0') Std deter_state: tensor(0.5488, device='cuda:0')
Mean prior_logit: tensor(-0.0642, device='cuda:0') Std prior_logit: tensor(0.5791, device='cuda:0')
Mean deter_state: tensor(0.0006, device='cuda:0') Std deter_state: tensor(0.5171, device='cuda:0')
Mean prior_logit: tensor(-0.0774, device='cuda:0') Std prior_logit: tensor(0.5301, device='cuda:0')
Mean deter_state: tensor(0.0001, device='cuda:0') Std deter_state: tensor(0.4985, device='cuda:0')
Mean prior_logit: tensor(-0.0826, device='cuda:0') Std prior_logit: tensor(0.5389, device='cuda:0')
Mean deter_state: tensor(0.0025, device='cuda:0') Std deter_state: tensor(0.5283, device='cuda:0')
Mean prior_logit: tensor(-0.0738, device='cuda:0') Std prior_logit: tensor(0.5458, device='cuda:0')
Mean deter_state: tensor(0.0026, device='cuda:0') Std deter_state: tensor(0.5298, device='cuda:0')
Mean prior_logit: tensor(-0.0672, device='cuda:0') Std prior_logit: tensor(0.5541, device='cuda:0')
Mean deter_state: tensor(0.0020, device='cuda:0') Std deter_state: tensor(0.5456, device='cuda:0')
Mean prior_logit: tensor(-0.0676, device='cuda:0') Std prior_logit: tensor(0.5568, device='cuda:0')
Mean deter_state: tensor(0.0016, device='cuda:0') Std deter_state: tensor(0.5265, device='cuda:0')
Mean prior_logit: tensor(-0.0737, device='cuda:0') Std prior_logit: tensor(0.5514, device='cuda:0')
Mean deter_state: tensor(-0.0092, device='cuda:0') Std deter_state: tensor(0.3609, device='cuda:0')
Mean prior_logit: tensor(-0.1600, device='cuda:0') Std prior_logit: tensor(0.6736, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4690, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0959, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5885, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0009, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4912, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0848, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5741, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0085, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3565, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1299, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5936, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0035, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4283, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0908, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5514, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0164, 0.0134, 0.0022, 0.0079, 0.0132, 0.0578, 0.3431, 0.0182, 0.4625,
        0.0046, 0.0561, 0.0046], device='cuda:0')
Mean deter_state: tensor(0.0049, device='cuda:0') Std deter_state: tensor(0.5633, device='cuda:0')
Mean prior_logit: tensor(-0.0589, device='cuda:0') Std prior_logit: tensor(0.5814, device='cuda:0')
Mean deter_state: tensor(0.0052, device='cuda:0') Std deter_state: tensor(0.4706, device='cuda:0')
Mean prior_logit: tensor(-0.0659, device='cuda:0') Std prior_logit: tensor(0.6001, device='cuda:0')
Mean deter_state: tensor(0.0030, device='cuda:0') Std deter_state: tensor(0.5361, device='cuda:0')
Mean prior_logit: tensor(-0.0723, device='cuda:0') Std prior_logit: tensor(0.5504, device='cuda:0')
Count of actions: (array([6, 8]), array([2, 4]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_21.gif
Eval_AverageReturn : -217.3000030517578
Eval_StdReturn : 213.13096618652344
Eval_MaxReturn : 95.0
Eval_MinReturn : -395.0
Eval_AverageEpLen : 199.1999969482422
Train_AverageReturn : -193.18182373046875
Train_StdReturn : 222.17562866210938
Train_MaxReturn : 95.0
Train_MinReturn : -400.0
Train_AverageEpLen : 186.18182373046875
Train_EnvstepsSoFar : 180224.0
TimeSinceStart : 4732.799766540527
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 89.22778396606445
Loss_Value : -0.5282016083598137
Loss_Entropy : 1.3395154148340225
Loss_Representation : 0.4615789264440536
Loss_KL : 3.002630037069321
Loss_Obs : -1.3978430122137069
Loss_Reward : -1.1766455920413137
Loss_Discount : 0.033437526086345315
Loss_RawKL : 2.8392298340797426
mean_target : -9.92737865447998
max_target : -9.888317561149597
min_target : -9.9562513589859
std_target : 0.0246000170474872
Done logging...

Current epsilon: 0.05493315728813243 at iteration 180224


********** Iteration 22 ************
Mean deter_state: tensor(-0.0003, device='cuda:0') Std deter_state: tensor(0.5089, device='cuda:0')
Mean prior_logit: tensor(-0.0744, device='cuda:0') Std prior_logit: tensor(0.5468, device='cuda:0')
Mean deter_state: tensor(-0.0148, device='cuda:0') Std deter_state: tensor(0.2964, device='cuda:0')
Mean prior_logit: tensor(-0.1505, device='cuda:0') Std prior_logit: tensor(0.6233, device='cuda:0')
Mean deter_state: tensor(-0.0019, device='cuda:0') Std deter_state: tensor(0.4855, device='cuda:0')
Mean prior_logit: tensor(-0.0813, device='cuda:0') Std prior_logit: tensor(0.5420, device='cuda:0')
Mean deter_state: tensor(-0.0140, device='cuda:0') Std deter_state: tensor(0.3703, device='cuda:0')
Mean prior_logit: tensor(-0.1503, device='cuda:0') Std prior_logit: tensor(0.6372, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.4845, device='cuda:0')
Mean prior_logit: tensor(-0.0784, device='cuda:0') Std prior_logit: tensor(0.5535, device='cuda:0')
Mean deter_state: tensor(-0.0109, device='cuda:0') Std deter_state: tensor(0.3057, device='cuda:0')
Mean prior_logit: tensor(-0.1421, device='cuda:0') Std prior_logit: tensor(0.6033, device='cuda:0')
Mean deter_state: tensor(-0.0039, device='cuda:0') Std deter_state: tensor(0.5270, device='cuda:0')
Mean prior_logit: tensor(-0.0822, device='cuda:0') Std prior_logit: tensor(0.5408, device='cuda:0')
Mean deter_state: tensor(-0.0009, device='cuda:0') Std deter_state: tensor(0.5291, device='cuda:0')
Mean prior_logit: tensor(-0.0764, device='cuda:0') Std prior_logit: tensor(0.5762, device='cuda:0')
Mean deter_state: tensor(0.0016, device='cuda:0') Std deter_state: tensor(0.5488, device='cuda:0')
Mean prior_logit: tensor(-0.0670, device='cuda:0') Std prior_logit: tensor(0.5646, device='cuda:0')
Mean deter_state: tensor(-0.0006, device='cuda:0') Std deter_state: tensor(0.5117, device='cuda:0')
Mean prior_logit: tensor(-0.0785, device='cuda:0') Std prior_logit: tensor(0.5528, device='cuda:0')
Mean deter_state: tensor(-0.0033, device='cuda:0') Std deter_state: tensor(0.4489, device='cuda:0')
Mean prior_logit: tensor(-0.1048, device='cuda:0') Std prior_logit: tensor(0.5245, device='cuda:0')
Mean deter_state: tensor(-0.0131, device='cuda:0') Std deter_state: tensor(0.3243, device='cuda:0')
Mean prior_logit: tensor(-0.1510, device='cuda:0') Std prior_logit: tensor(0.6323, device='cuda:0')
Mean deter_state: tensor(-0.0152, device='cuda:0') Std deter_state: tensor(0.3060, device='cuda:0')
Mean prior_logit: tensor(-0.1548, device='cuda:0') Std prior_logit: tensor(0.6455, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0') Std deter_state: tensor(0.3885, device='cuda:0')
Mean prior_logit: tensor(-0.0739, device='cuda:0') Std prior_logit: tensor(0.5909, device='cuda:0')
Mean deter_state: tensor(-0.0003, device='cuda:0') Std deter_state: tensor(0.4999, device='cuda:0')
Mean prior_logit: tensor(-0.0775, device='cuda:0') Std prior_logit: tensor(0.5436, device='cuda:0')
Mean deter_state: tensor(-0.0030, device='cuda:0') Std deter_state: tensor(0.3680, device='cuda:0')
Mean prior_logit: tensor(-0.0938, device='cuda:0') Std prior_logit: tensor(0.5702, device='cuda:0')
Mean deter_state: tensor(-0.0140, device='cuda:0') Std deter_state: tensor(0.3890, device='cuda:0')
Mean prior_logit: tensor(-0.1474, device='cuda:0') Std prior_logit: tensor(0.6314, device='cuda:0')
Mean deter_state: tensor(-0.0015, device='cuda:0') Std deter_state: tensor(0.4797, device='cuda:0')
Mean prior_logit: tensor(-0.0857, device='cuda:0') Std prior_logit: tensor(0.5314, device='cuda:0')
Mean deter_state: tensor(-0.0008, device='cuda:0') Std deter_state: tensor(0.5096, device='cuda:0')
Mean prior_logit: tensor(-0.0683, device='cuda:0') Std prior_logit: tensor(0.5694, device='cuda:0')
Mean deter_state: tensor(-0.0001, device='cuda:0') Std deter_state: tensor(0.5027, device='cuda:0')
Mean prior_logit: tensor(-0.0809, device='cuda:0') Std prior_logit: tensor(0.5323, device='cuda:0')
Imagined rewards:  tensor([-0.0068, -0.0176, -0.0743, -0.1047, -0.1032, -0.1046, -0.1029, -0.1092,
        -0.1000, -0.1076], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([ -9.2734,  -9.7822, -10.0238, -10.1097, -10.1000, -10.0835, -10.0540,
        -10.0262,  -9.9874], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([ -9.2734,  -9.7822, -10.0238, -10.1097, -10.1000, -10.0835, -10.0540,
        -10.0262,  -9.9874], device='cuda:0', grad_fn=<SelectBackward0>)
Mean deter_state: tensor(-0.0090, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3522, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1312, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5962, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4512, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0929, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5747, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0054, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3982, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1125, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5833, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0065, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4017, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1158, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5698, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0264, 0.0200, 0.0056, 0.0139, 0.0193, 0.0786, 0.3574, 0.0257, 0.3570,
        0.0107, 0.0787, 0.0069], device='cuda:0')
Mean deter_state: tensor(-0.0070, device='cuda:0') Std deter_state: tensor(0.4305, device='cuda:0')
Mean prior_logit: tensor(-0.1073, device='cuda:0') Std prior_logit: tensor(0.5407, device='cuda:0')
Mean deter_state: tensor(-0.0023, device='cuda:0') Std deter_state: tensor(0.4304, device='cuda:0')
Mean prior_logit: tensor(-0.0772, device='cuda:0') Std prior_logit: tensor(0.5761, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([ 6,  7,  3, 15, 11, 27, 76, 12, 88,  7, 45,  3]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_22.gif
Eval_AverageReturn : -172.3000030517578
Eval_StdReturn : 220.5076141357422
Eval_MaxReturn : 76.0
Eval_MinReturn : -395.0
Eval_AverageEpLen : 171.8000030517578
Train_AverageReturn : -162.86000061035156
Train_StdReturn : 227.40296936035156
Train_MaxReturn : 95.0
Train_MinReturn : -395.0
Train_AverageEpLen : 163.83999633789062
Train_EnvstepsSoFar : 188416.0
TimeSinceStart : 4949.072633743286
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 90.17293300628663
Loss_Value : -0.5057992973946966
Loss_Entropy : 1.534253540635109
Loss_Representation : 0.17116636633872986
Loss_KL : 3.0
Loss_Obs : -1.351561239361763
Loss_Reward : -1.5165326043963432
Loss_Discount : 0.039260213589295746
Loss_RawKL : 2.614539796113968
mean_target : -10.034214234352111
max_target : -9.989864563941955
min_target : -10.072987627983093
std_target : 0.031387793947942555
Done logging...

Current epsilon: 0.05390368923530522 at iteration 188416


********** Iteration 23 ************
Mean deter_state: tensor(-0.0007, device='cuda:0') Std deter_state: tensor(0.4894, device='cuda:0')
Mean prior_logit: tensor(-0.0808, device='cuda:0') Std prior_logit: tensor(0.5573, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.4657, device='cuda:0')
Mean prior_logit: tensor(-0.0885, device='cuda:0') Std prior_logit: tensor(0.5281, device='cuda:0')
Mean deter_state: tensor(-0.0018, device='cuda:0') Std deter_state: tensor(0.4628, device='cuda:0')
Mean prior_logit: tensor(-0.0828, device='cuda:0') Std prior_logit: tensor(0.5313, device='cuda:0')
Mean deter_state: tensor(-0.0023, device='cuda:0') Std deter_state: tensor(0.4945, device='cuda:0')
Mean prior_logit: tensor(-0.0940, device='cuda:0') Std prior_logit: tensor(0.5615, device='cuda:0')
Mean deter_state: tensor(-0.0143, device='cuda:0') Std deter_state: tensor(0.3040, device='cuda:0')
Mean prior_logit: tensor(-0.1490, device='cuda:0') Std prior_logit: tensor(0.6131, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.4861, device='cuda:0')
Mean prior_logit: tensor(-0.0705, device='cuda:0') Std prior_logit: tensor(0.5768, device='cuda:0')
Mean deter_state: tensor(-0.0056, device='cuda:0') Std deter_state: tensor(0.4393, device='cuda:0')
Mean prior_logit: tensor(-0.1076, device='cuda:0') Std prior_logit: tensor(0.5360, device='cuda:0')
Mean deter_state: tensor(0.0028, device='cuda:0') Std deter_state: tensor(0.5107, device='cuda:0')
Mean prior_logit: tensor(-0.0692, device='cuda:0') Std prior_logit: tensor(0.5663, device='cuda:0')
Mean deter_state: tensor(-0.0004, device='cuda:0') Std deter_state: tensor(0.4969, device='cuda:0')
Mean prior_logit: tensor(-0.0848, device='cuda:0') Std prior_logit: tensor(0.5444, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0') Std deter_state: tensor(0.4732, device='cuda:0')
Mean prior_logit: tensor(-0.0951, device='cuda:0') Std prior_logit: tensor(0.5373, device='cuda:0')
Mean deter_state: tensor(-0.0008, device='cuda:0') Std deter_state: tensor(0.3880, device='cuda:0')
Mean prior_logit: tensor(-0.0894, device='cuda:0') Std prior_logit: tensor(0.5810, device='cuda:0')
Mean deter_state: tensor(-0.0013, device='cuda:0') Std deter_state: tensor(0.5017, device='cuda:0')
Mean prior_logit: tensor(-0.0801, device='cuda:0') Std prior_logit: tensor(0.5425, device='cuda:0')
Mean deter_state: tensor(-0.0023, device='cuda:0') Std deter_state: tensor(0.4873, device='cuda:0')
Mean prior_logit: tensor(-0.0868, device='cuda:0') Std prior_logit: tensor(0.5507, device='cuda:0')
Mean deter_state: tensor(-0.0137, device='cuda:0') Std deter_state: tensor(0.3326, device='cuda:0')
Mean prior_logit: tensor(-0.1510, device='cuda:0') Std prior_logit: tensor(0.6311, device='cuda:0')
Mean deter_state: tensor(-0.0032, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4367, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0892, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5457, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0038, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4333, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1009, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5683, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4537, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0915, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5607, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0018, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4525, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0933, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5741, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0275, 0.0228, 0.0076, 0.0152, 0.0192, 0.0833, 0.3065, 0.0278, 0.3954,
        0.0147, 0.0726, 0.0073], device='cuda:0')
Mean deter_state: tensor(0.0032, device='cuda:0') Std deter_state: tensor(0.5233, device='cuda:0')
Mean prior_logit: tensor(-0.0795, device='cuda:0') Std prior_logit: tensor(0.5506, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([25,  9,  7, 12, 11, 27, 59, 18, 83, 11, 33,  5]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_23.gif
Eval_AverageReturn : -154.6999969482422
Eval_StdReturn : 235.4549102783203
Eval_MaxReturn : 95.0
Eval_MinReturn : -390.0
Eval_AverageEpLen : 158.6999969482422
Train_AverageReturn : -186.02174377441406
Train_StdReturn : 228.46495056152344
Train_MaxReturn : 95.0
Train_MinReturn : -395.0
Train_AverageEpLen : 178.0869598388672
Train_EnvstepsSoFar : 196608.0
TimeSinceStart : 5162.608030080795
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 91.01798648834229
Loss_Value : -0.5314787954092026
Loss_Entropy : 1.525670412182808
Loss_Representation : 0.27814675569534303
Loss_KL : 3.0
Loss_Obs : -1.3767604500055313
Loss_Reward : -1.3819900684058666
Loss_Discount : 0.036897242069244385
Loss_RawKL : 2.6891947865486143
mean_target : -10.127962160110474
max_target : -10.080849504470825
min_target : -10.169808053970337
std_target : 0.03361622132360935
Done logging...

Current epsilon: 0.05308905407952376 at iteration 196608


********** Iteration 24 ************
Mean deter_state: tensor(-0.0120, device='cuda:0') Std deter_state: tensor(0.3483, device='cuda:0')
Mean prior_logit: tensor(-0.1533, device='cuda:0') Std prior_logit: tensor(0.6494, device='cuda:0')
Mean deter_state: tensor(-0.0158, device='cuda:0') Std deter_state: tensor(0.3036, device='cuda:0')
Mean prior_logit: tensor(-0.1405, device='cuda:0') Std prior_logit: tensor(0.5995, device='cuda:0')
Mean deter_state: tensor(-0.0015, device='cuda:0') Std deter_state: tensor(0.4637, device='cuda:0')
Mean prior_logit: tensor(-0.0937, device='cuda:0') Std prior_logit: tensor(0.5327, device='cuda:0')
Mean deter_state: tensor(-0.0178, device='cuda:0') Std deter_state: tensor(0.3201, device='cuda:0')
Mean prior_logit: tensor(-0.1572, device='cuda:0') Std prior_logit: tensor(0.6450, device='cuda:0')
Mean deter_state: tensor(-0.0014, device='cuda:0') Std deter_state: tensor(0.3477, device='cuda:0')
Mean prior_logit: tensor(-0.0931, device='cuda:0') Std prior_logit: tensor(0.5672, device='cuda:0')
Mean deter_state: tensor(-0.0139, device='cuda:0') Std deter_state: tensor(0.3401, device='cuda:0')
Mean prior_logit: tensor(-0.1664, device='cuda:0') Std prior_logit: tensor(0.6906, device='cuda:0')
Mean deter_state: tensor(0.0017, device='cuda:0') Std deter_state: tensor(0.5043, device='cuda:0')
Mean prior_logit: tensor(-0.0729, device='cuda:0') Std prior_logit: tensor(0.5444, device='cuda:0')
Mean deter_state: tensor(-0.0150, device='cuda:0') Std deter_state: tensor(0.3157, device='cuda:0')
Mean prior_logit: tensor(-0.1558, device='cuda:0') Std prior_logit: tensor(0.6507, device='cuda:0')
Mean deter_state: tensor(-0.0150, device='cuda:0') Std deter_state: tensor(0.3515, device='cuda:0')
Mean prior_logit: tensor(-0.1616, device='cuda:0') Std prior_logit: tensor(0.6789, device='cuda:0')
Mean deter_state: tensor(-0.0013, device='cuda:0') Std deter_state: tensor(0.3852, device='cuda:0')
Mean prior_logit: tensor(-0.0743, device='cuda:0') Std prior_logit: tensor(0.5874, device='cuda:0')
Mean deter_state: tensor(-0.0025, device='cuda:0') Std deter_state: tensor(0.4404, device='cuda:0')
Mean prior_logit: tensor(-0.1009, device='cuda:0') Std prior_logit: tensor(0.5426, device='cuda:0')
Mean deter_state: tensor(-0.0012, device='cuda:0') Std deter_state: tensor(0.4855, device='cuda:0')
Mean prior_logit: tensor(-0.0896, device='cuda:0') Std prior_logit: tensor(0.5387, device='cuda:0')
Mean deter_state: tensor(0.0016, device='cuda:0') Std deter_state: tensor(0.5339, device='cuda:0')
Mean prior_logit: tensor(-0.0632, device='cuda:0') Std prior_logit: tensor(0.5641, device='cuda:0')
Mean deter_state: tensor(0.0009, device='cuda:0') Std deter_state: tensor(0.5370, device='cuda:0')
Mean prior_logit: tensor(-0.0575, device='cuda:0') Std prior_logit: tensor(0.5991, device='cuda:0')
Mean deter_state: tensor(0.0033, device='cuda:0') Std deter_state: tensor(0.5138, device='cuda:0')
Mean prior_logit: tensor(-0.0729, device='cuda:0') Std prior_logit: tensor(0.5466, device='cuda:0')
Mean deter_state: tensor(0.0014, device='cuda:0') Std deter_state: tensor(0.5274, device='cuda:0')
Mean prior_logit: tensor(-0.0770, device='cuda:0') Std prior_logit: tensor(0.5442, device='cuda:0')
Mean deter_state: tensor(-0.0035, device='cuda:0') Std deter_state: tensor(0.4691, device='cuda:0')
Mean prior_logit: tensor(-0.0988, device='cuda:0') Std prior_logit: tensor(0.5347, device='cuda:0')
Mean deter_state: tensor(-0.0022, device='cuda:0') Std deter_state: tensor(0.3984, device='cuda:0')
Mean prior_logit: tensor(-0.0875, device='cuda:0') Std prior_logit: tensor(0.5967, device='cuda:0')
Mean deter_state: tensor(-0.0016, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3028, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0626, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4471, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4823, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0878, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5794, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3590, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1324, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.6014, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0028, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4555, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0954, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5787, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0026, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4690, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0934, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5845, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3752, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0741, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5130, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0298, 0.0267, 0.0093, 0.0172, 0.0204, 0.0950, 0.2815, 0.0324, 0.3842,
        0.0198, 0.0753, 0.0083], device='cuda:0')
Mean deter_state: tensor(0.0050, device='cuda:0') Std deter_state: tensor(0.4911, device='cuda:0')
Mean prior_logit: tensor(-0.0683, device='cuda:0') Std prior_logit: tensor(0.6047, device='cuda:0')
Mean deter_state: tensor(0.0038, device='cuda:0') Std deter_state: tensor(0.5584, device='cuda:0')
Mean prior_logit: tensor(-0.0614, device='cuda:0') Std prior_logit: tensor(0.5858, device='cuda:0')
Mean deter_state: tensor(-0.0129, device='cuda:0') Std deter_state: tensor(0.2817, device='cuda:0')
Mean prior_logit: tensor(-0.1405, device='cuda:0') Std prior_logit: tensor(0.5814, device='cuda:0')
Mean deter_state: tensor(-0.0164, device='cuda:0') Std deter_state: tensor(0.3435, device='cuda:0')
Mean prior_logit: tensor(-0.1533, device='cuda:0') Std prior_logit: tensor(0.6438, device='cuda:0')
Count of actions: (array([0, 2, 4, 5, 6, 7, 8]), array([2, 1, 2, 3, 2, 2, 8]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_24.gif
Eval_AverageReturn : -295.1000061035156
Eval_StdReturn : 183.83984375
Eval_MaxReturn : 94.0
Eval_MinReturn : -395.0
Eval_AverageEpLen : 244.8000030517578
Train_AverageReturn : -250.15789794921875
Train_StdReturn : 208.2068328857422
Train_MaxReturn : 95.0
Train_MinReturn : -395.0
Train_AverageEpLen : 215.57894897460938
Train_EnvstepsSoFar : 204800.0
TimeSinceStart : 5383.330983877182
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 91.77595558166504
Loss_Value : -0.5554933380335569
Loss_Entropy : 1.5796760618686676
Loss_Representation : 0.1546952933073044
Loss_KL : 3.0
Loss_Obs : -1.386452916264534
Loss_Reward : -1.489334611594677
Loss_Discount : 0.03048282447271049
Loss_RawKL : 2.7274520099163055
mean_target : -10.212715601921081
max_target : -10.15999071598053
min_target : -10.259278082847596
std_target : 0.03711232964415103
Done logging...

Current epsilon: 0.05244441976065144 at iteration 204800


********** Iteration 25 ************
Mean deter_state: tensor(-0.0139, device='cuda:0') Std deter_state: tensor(0.3013, device='cuda:0')
Mean prior_logit: tensor(-0.1495, device='cuda:0') Std prior_logit: tensor(0.6226, device='cuda:0')
Mean deter_state: tensor(0.0017, device='cuda:0') Std deter_state: tensor(0.4562, device='cuda:0')
Mean prior_logit: tensor(-0.0824, device='cuda:0') Std prior_logit: tensor(0.5909, device='cuda:0')
Mean deter_state: tensor(-0.0028, device='cuda:0') Std deter_state: tensor(0.4855, device='cuda:0')
Mean prior_logit: tensor(-0.0864, device='cuda:0') Std prior_logit: tensor(0.5387, device='cuda:0')
Mean deter_state: tensor(0.0009, device='cuda:0') Std deter_state: tensor(0.5217, device='cuda:0')
Mean prior_logit: tensor(-0.0708, device='cuda:0') Std prior_logit: tensor(0.5689, device='cuda:0')
Mean deter_state: tensor(0.0013, device='cuda:0') Std deter_state: tensor(0.4659, device='cuda:0')
Mean prior_logit: tensor(-0.0752, device='cuda:0') Std prior_logit: tensor(0.5651, device='cuda:0')
Mean deter_state: tensor(-0.0041, device='cuda:0') Std deter_state: tensor(0.4832, device='cuda:0')
Mean prior_logit: tensor(-0.0931, device='cuda:0') Std prior_logit: tensor(0.5338, device='cuda:0')
Mean deter_state: tensor(0.0002, device='cuda:0') Std deter_state: tensor(0.4740, device='cuda:0')
Mean prior_logit: tensor(-0.0690, device='cuda:0') Std prior_logit: tensor(0.5750, device='cuda:0')
Mean deter_state: tensor(-0.0107, device='cuda:0') Std deter_state: tensor(0.3792, device='cuda:0')
Mean prior_logit: tensor(-0.1427, device='cuda:0') Std prior_logit: tensor(0.6128, device='cuda:0')
Mean deter_state: tensor(0.0001, device='cuda:0') Std deter_state: tensor(0.5063, device='cuda:0')
Mean prior_logit: tensor(-0.0750, device='cuda:0') Std prior_logit: tensor(0.5299, device='cuda:0')
Mean deter_state: tensor(0.0014, device='cuda:0') Std deter_state: tensor(0.5179, device='cuda:0')
Mean prior_logit: tensor(-0.0810, device='cuda:0') Std prior_logit: tensor(0.5468, device='cuda:0')
Mean deter_state: tensor(-0.0026, device='cuda:0') Std deter_state: tensor(0.4897, device='cuda:0')
Mean prior_logit: tensor(-0.0847, device='cuda:0') Std prior_logit: tensor(0.5390, device='cuda:0')
Mean deter_state: tensor(-0.0116, device='cuda:0') Std deter_state: tensor(0.3065, device='cuda:0')
Mean prior_logit: tensor(-0.1487, device='cuda:0') Std prior_logit: tensor(0.6265, device='cuda:0')
Mean deter_state: tensor(0.0012, device='cuda:0') Std deter_state: tensor(0.5251, device='cuda:0')
Mean prior_logit: tensor(-0.0706, device='cuda:0') Std prior_logit: tensor(0.5622, device='cuda:0')
Mean deter_state: tensor(-0.0171, device='cuda:0') Std deter_state: tensor(0.3273, device='cuda:0')
Mean prior_logit: tensor(-0.1650, device='cuda:0') Std prior_logit: tensor(0.6853, device='cuda:0')
Mean deter_state: tensor(-0.0048, device='cuda:0') Std deter_state: tensor(0.3821, device='cuda:0')
Mean prior_logit: tensor(-0.1045, device='cuda:0') Std prior_logit: tensor(0.5925, device='cuda:0')
Mean deter_state: tensor(0.0024, device='cuda:0') Std deter_state: tensor(0.5071, device='cuda:0')
Mean prior_logit: tensor(-0.0763, device='cuda:0') Std prior_logit: tensor(0.5580, device='cuda:0')
Mean deter_state: tensor(0.0042, device='cuda:0') Std deter_state: tensor(0.5338, device='cuda:0')
Mean prior_logit: tensor(-0.0612, device='cuda:0') Std prior_logit: tensor(0.5878, device='cuda:0')
Mean deter_state: tensor(-0.0052, device='cuda:0') Std deter_state: tensor(0.5115, device='cuda:0')
Mean prior_logit: tensor(-0.0836, device='cuda:0') Std prior_logit: tensor(0.5408, device='cuda:0')
Mean deter_state: tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4663, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0951, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5724, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3696, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0794, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5248, device='cuda:0', grad_fn=<StdBackward0>)
Imagined rewards:  tensor([-0.0951, -0.1084, -0.1144, -0.1138, -0.1139, -0.1158, -0.1137, -0.1141,
        -0.0822, -0.0584], device='cuda:0', grad_fn=<SelectBackward0>)
Loss total:  tensor([-10.2738, -10.3790, -10.3877, -10.3516, -10.2994, -10.2514, -10.2067,
        -10.1630, -10.1234], device='cuda:0', grad_fn=<SelectBackward0>)
Discounted loss total:  tensor([-10.2738, -10.3790, -10.3877, -10.3516, -10.2994, -10.2514, -10.2067,
        -10.1630, -10.1234], device='cuda:0', grad_fn=<SelectBackward0>)
Current action distribution:
tensor([0.0309, 0.0280, 0.0087, 0.0173, 0.0200, 0.1247, 0.3028, 0.0350, 0.3114,
        0.0220, 0.0904, 0.0089], device='cuda:0')
Mean deter_state: tensor(-0.0010, device='cuda:0') Std deter_state: tensor(0.4752, device='cuda:0')
Mean prior_logit: tensor(-0.0935, device='cuda:0') Std prior_logit: tensor(0.5422, device='cuda:0')
Mean deter_state: tensor(0.0015, device='cuda:0') Std deter_state: tensor(0.5121, device='cuda:0')
Mean prior_logit: tensor(-0.0820, device='cuda:0') Std prior_logit: tensor(0.5489, device='cuda:0')
Mean deter_state: tensor(-0.0002, device='cuda:0') Std deter_state: tensor(0.4727, device='cuda:0')
Mean prior_logit: tensor(-0.0934, device='cuda:0') Std prior_logit: tensor(0.5461, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([17, 14,  4, 14, 11, 45, 58, 11, 64, 13, 47,  2]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_25.gif
Eval_AverageReturn : -297.0
Eval_StdReturn : 182.66143798828125
Eval_MaxReturn : 94.0
Eval_MinReturn : -395.0
Eval_AverageEpLen : 245.6999969482422
Train_AverageReturn : -179.70213317871094
Train_StdReturn : 226.88885498046875
Train_MaxReturn : 95.0
Train_MinReturn : -395.0
Train_AverageEpLen : 174.29786682128906
Train_EnvstepsSoFar : 212992.0
TimeSinceStart : 5610.327926635742
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 92.75669612884522
Loss_Value : -0.5832470525056124
Loss_Entropy : 1.665416195988655
Loss_Representation : 0.013131403923034668
Loss_KL : 3.0
Loss_Obs : -1.3945033609867097
Loss_Reward : -1.6299435392022132
Loss_Discount : 0.03757830611430109
Loss_RawKL : 2.797678130865097
mean_target : -10.322610473632812
max_target : -10.261377692222595
min_target : -10.372874999046326
std_target : 0.041055999044328925
Done logging...

Current epsilon: 0.051934309925446315 at iteration 212992


********** Iteration 26 ************
Mean deter_state: tensor(-0.0034, device='cuda:0') Std deter_state: tensor(0.3612, device='cuda:0')
Mean prior_logit: tensor(-0.0929, device='cuda:0') Std prior_logit: tensor(0.5795, device='cuda:0')
Mean deter_state: tensor(-0.0013, device='cuda:0') Std deter_state: tensor(0.4961, device='cuda:0')
Mean prior_logit: tensor(-0.0877, device='cuda:0') Std prior_logit: tensor(0.5461, device='cuda:0')
Mean deter_state: tensor(0.0031, device='cuda:0') Std deter_state: tensor(0.5405, device='cuda:0')
Mean prior_logit: tensor(-0.0659, device='cuda:0') Std prior_logit: tensor(0.5750, device='cuda:0')
Mean deter_state: tensor(-0.0157, device='cuda:0') Std deter_state: tensor(0.3117, device='cuda:0')
Mean prior_logit: tensor(-0.1584, device='cuda:0') Std prior_logit: tensor(0.6537, device='cuda:0')
Mean deter_state: tensor(-0.0096, device='cuda:0') Std deter_state: tensor(0.3514, device='cuda:0')
Mean prior_logit: tensor(-0.1582, device='cuda:0') Std prior_logit: tensor(0.6675, device='cuda:0')
Mean deter_state: tensor(-0.0010, device='cuda:0') Std deter_state: tensor(0.5270, device='cuda:0')
Mean prior_logit: tensor(-0.0732, device='cuda:0') Std prior_logit: tensor(0.5586, device='cuda:0')
Mean deter_state: tensor(-0.0178, device='cuda:0') Std deter_state: tensor(0.3531, device='cuda:0')
Mean prior_logit: tensor(-0.1614, device='cuda:0') Std prior_logit: tensor(0.6766, device='cuda:0')
Mean deter_state: tensor(-0.0020, device='cuda:0') Std deter_state: tensor(0.5042, device='cuda:0')
Mean prior_logit: tensor(-0.0853, device='cuda:0') Std prior_logit: tensor(0.5475, device='cuda:0')
Mean deter_state: tensor(-0.0160, device='cuda:0') Std deter_state: tensor(0.3139, device='cuda:0')
Mean prior_logit: tensor(-0.1526, device='cuda:0') Std prior_logit: tensor(0.6412, device='cuda:0')
Mean deter_state: tensor(-0.0148, device='cuda:0') Std deter_state: tensor(0.3382, device='cuda:0')
Mean prior_logit: tensor(-0.1707, device='cuda:0') Std prior_logit: tensor(0.7088, device='cuda:0')
Mean deter_state: tensor(-0.0087, device='cuda:0') Std deter_state: tensor(0.1997, device='cuda:0')
Mean prior_logit: tensor(-0.1142, device='cuda:0') Std prior_logit: tensor(0.4659, device='cuda:0')
Mean deter_state: tensor(-0.0148, device='cuda:0') Std deter_state: tensor(0.3109, device='cuda:0')
Mean prior_logit: tensor(-0.1474, device='cuda:0') Std prior_logit: tensor(0.6257, device='cuda:0')
Mean deter_state: tensor(-0.0181, device='cuda:0') Std deter_state: tensor(0.3246, device='cuda:0')
Mean prior_logit: tensor(-0.1625, device='cuda:0') Std prior_logit: tensor(0.6678, device='cuda:0')
Mean deter_state: tensor(-0.0030, device='cuda:0') Std deter_state: tensor(0.4857, device='cuda:0')
Mean prior_logit: tensor(-0.0880, device='cuda:0') Std prior_logit: tensor(0.5344, device='cuda:0')
Mean deter_state: tensor(0.0025, device='cuda:0') Std deter_state: tensor(0.5566, device='cuda:0')
Mean prior_logit: tensor(-0.0625, device='cuda:0') Std prior_logit: tensor(0.5706, device='cuda:0')
Mean deter_state: tensor(-0.0029, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4537, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1013, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5909, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0087, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3753, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1306, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5978, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0014, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4854, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0908, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5781, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0041, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4510, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.1038, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5933, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(0.0001, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3217, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0551, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.4510, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0011, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.2054, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0411, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.3220, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0019, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.0398, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0184, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0970, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0320, 0.0290, 0.0089, 0.0176, 0.0203, 0.1454, 0.2781, 0.0380, 0.2961,
        0.0247, 0.1007, 0.0092], device='cuda:0')
Mean deter_state: tensor(0.0019, device='cuda:0') Std deter_state: tensor(0.5252, device='cuda:0')
Mean prior_logit: tensor(-0.0749, device='cuda:0') Std prior_logit: tensor(0.5480, device='cuda:0')
Mean deter_state: tensor(-0.0104, device='cuda:0') Std deter_state: tensor(0.3542, device='cuda:0')
Mean prior_logit: tensor(-0.1551, device='cuda:0') Std prior_logit: tensor(0.6519, device='cuda:0')
Mean deter_state: tensor(-0.0152, device='cuda:0') Std deter_state: tensor(0.3491, device='cuda:0')
Mean prior_logit: tensor(-0.1722, device='cuda:0') Std prior_logit: tensor(0.7192, device='cuda:0')
Mean deter_state: tensor(-0.0148, device='cuda:0') Std deter_state: tensor(0.3254, device='cuda:0')
Mean prior_logit: tensor(-0.1621, device='cuda:0') Std prior_logit: tensor(0.6731, device='cuda:0')
Mean deter_state: tensor(0.0019, device='cuda:0') Std deter_state: tensor(0.4600, device='cuda:0')
Mean prior_logit: tensor(-0.0741, device='cuda:0') Std prior_logit: tensor(0.5760, device='cuda:0')
Mean deter_state: tensor(0.0008, device='cuda:0') Std deter_state: tensor(0.5256, device='cuda:0')
Mean prior_logit: tensor(-0.0693, device='cuda:0') Std prior_logit: tensor(0.5682, device='cuda:0')
Mean deter_state: tensor(-0.0024, device='cuda:0') Std deter_state: tensor(0.5050, device='cuda:0')
Mean prior_logit: tensor(-0.0903, device='cuda:0') Std prior_logit: tensor(0.5456, device='cuda:0')
Count of actions: (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), array([10, 15, 12, 13, 11, 44, 47, 15, 64, 18, 48,  3]))
Saved episode GIF to ./logs/tb_dreamerv2_basic_2/episode_26.gif
Eval_AverageReturn : -176.3000030517578
Eval_StdReturn : 214.47845458984375
Eval_MaxReturn : 95.0
Eval_MinReturn : -390.0
Eval_AverageEpLen : 175.8000030517578
Train_AverageReturn : -200.7954559326172
Train_StdReturn : 225.9361114501953
Train_MaxReturn : 95.0
Train_MinReturn : -395.0
Train_AverageEpLen : 186.18182373046875
Train_EnvstepsSoFar : 221184.0
TimeSinceStart : 5826.5283353328705
Initial_DataCollection_AverageReturn : -206.39535522460938
Loss_Policy : 93.49887981414795
Loss_Value : -0.6540828384459019
Loss_Entropy : 1.7057993292808533
Loss_Representation : -0.12161461412906646
Loss_KL : 3.0
Loss_Obs : -1.3968803197145463
Loss_Reward : -1.7583022635430097
Loss_Discount : 0.03356797336600721
Loss_RawKL : 2.8083582758903503
mean_target : -10.405503606796264
max_target : -10.345585608482361
min_target : -10.455543279647827
std_target : 0.040604777098633346
Done logging...

Current epsilon: 0.0515306515468043 at iteration 221184


********** Iteration 27 ************
Mean deter_state: tensor(-0.0125, device='cuda:0') Std deter_state: tensor(0.3971, device='cuda:0')
Mean prior_logit: tensor(-0.1467, device='cuda:0') Std prior_logit: tensor(0.6300, device='cuda:0')
Mean deter_state: tensor(-0.0048, device='cuda:0') Std deter_state: tensor(0.4706, device='cuda:0')
Mean prior_logit: tensor(-0.0897, device='cuda:0') Std prior_logit: tensor(0.5305, device='cuda:0')
Mean deter_state: tensor(-0.0114, device='cuda:0') Std deter_state: tensor(0.2068, device='cuda:0')
Mean prior_logit: tensor(-0.1146, device='cuda:0') Std prior_logit: tensor(0.4644, device='cuda:0')
Mean deter_state: tensor(-0.0105, device='cuda:0') Std deter_state: tensor(0.2669, device='cuda:0')
Mean prior_logit: tensor(-0.1384, device='cuda:0') Std prior_logit: tensor(0.5739, device='cuda:0')
Mean deter_state: tensor(0.0006, device='cuda:0') Std deter_state: tensor(0.4658, device='cuda:0')
Mean prior_logit: tensor(-0.1007, device='cuda:0') Std prior_logit: tensor(0.5333, device='cuda:0')
Mean deter_state: tensor(0.0023, device='cuda:0') Std deter_state: tensor(0.5228, device='cuda:0')
Mean prior_logit: tensor(-0.0655, device='cuda:0') Std prior_logit: tensor(0.5780, device='cuda:0')
Mean deter_state: tensor(-0.0017, device='cuda:0') Std deter_state: tensor(0.5096, device='cuda:0')
Mean prior_logit: tensor(-0.0677, device='cuda:0') Std prior_logit: tensor(0.5865, device='cuda:0')
Mean deter_state: tensor(-0.0023, device='cuda:0') Std deter_state: tensor(0.4925, device='cuda:0')
Mean prior_logit: tensor(-0.0862, device='cuda:0') Std prior_logit: tensor(0.5367, device='cuda:0')
Mean deter_state: tensor(-0.0120, device='cuda:0') Std deter_state: tensor(0.4013, device='cuda:0')
Mean prior_logit: tensor(-0.1353, device='cuda:0') Std prior_logit: tensor(0.5899, device='cuda:0')
Mean deter_state: tensor(0.0007, device='cuda:0') Std deter_state: tensor(0.4719, device='cuda:0')
Mean prior_logit: tensor(-0.0701, device='cuda:0') Std prior_logit: tensor(0.6017, device='cuda:0')
Mean deter_state: tensor(0.0030, device='cuda:0') Std deter_state: tensor(0.5089, device='cuda:0')
Mean prior_logit: tensor(-0.0787, device='cuda:0') Std prior_logit: tensor(0.5561, device='cuda:0')
Mean deter_state: tensor(0.0003, device='cuda:0') Std deter_state: tensor(0.4799, device='cuda:0')
Mean prior_logit: tensor(-0.0871, device='cuda:0') Std prior_logit: tensor(0.5364, device='cuda:0')
Mean deter_state: tensor(-0.0065, device='cuda:0') Std deter_state: tensor(0.4390, device='cuda:0')
Mean prior_logit: tensor(-0.1049, device='cuda:0') Std prior_logit: tensor(0.5462, device='cuda:0')
Mean deter_state: tensor(0.0002, device='cuda:0') Std deter_state: tensor(0.5014, device='cuda:0')
Mean prior_logit: tensor(-0.0619, device='cuda:0') Std prior_logit: tensor(0.6033, device='cuda:0')
Mean deter_state: tensor(-0.0029, device='cuda:0') Std deter_state: tensor(0.4960, device='cuda:0')
Mean prior_logit: tensor(-0.0851, device='cuda:0') Std prior_logit: tensor(0.5421, device='cuda:0')
Mean deter_state: tensor(0.0043, device='cuda:0') Std deter_state: tensor(0.5546, device='cuda:0')
Mean prior_logit: tensor(-0.0691, device='cuda:0') Std prior_logit: tensor(0.5772, device='cuda:0')
Mean deter_state: tensor(-0.0024, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.3925, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0842, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5221, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.4858, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0814, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.5758, device='cuda:0', grad_fn=<StdBackward0>)
Mean deter_state: tensor(-0.0020, device='cuda:0', grad_fn=<MeanBackward0>) Std deter_state: tensor(0.0401, device='cuda:0', grad_fn=<StdBackward0>)
Mean prior_logit: tensor(-0.0186, device='cuda:0', grad_fn=<MeanBackward0>) Std prior_logit: tensor(0.0980, device='cuda:0', grad_fn=<StdBackward0>)
Current action distribution:
tensor([0.0337, 0.0289, 0.0087, 0.0177, 0.0205, 0.1737, 0.2388, 0.0404, 0.2832,
        0.0262, 0.1187, 0.0095], device='cuda:0')
Mean deter_state: tensor(-0.0029, device='cuda:0') Std deter_state: tensor(0.3767, device='cuda:0')
Mean prior_logit: tensor(-0.0948, device='cuda:0') Std prior_logit: tensor(0.5811, device='cuda:0')
Mean deter_state: tensor(-0.0050, device='cuda:0') Std deter_state: tensor(0.3943, device='cuda:0')
Mean prior_logit: tensor(-0.0964, device='cuda:0') Std prior_logit: tensor(0.5836, device='cuda:0')
Mean deter_state: tensor(0.0018, device='cuda:0') Std deter_state: tensor(0.5205, device='cuda:0')
Mean prior_logit: tensor(-0.0706, device='cuda:0') Std prior_logit: tensor(0.5655, device='cuda:0')
